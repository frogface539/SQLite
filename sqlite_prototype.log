2025-05-03 15:19:00,799 - compiler.tokenizer - ERROR - Invalid token at 0: &
2025-05-03 15:19:00,799 - __main__ - ERROR - Error: Invalid token at 0: &
2025-05-03 15:23:08,461 - compiler.tokenizer - ERROR - Invalid token at 0: &
2025-05-03 15:23:08,461 - __main__ - ERROR - Error: Invalid token at 0: &
2025-05-03 15:23:20,655 - compiler.tokenizer - DEBUG - KEYWORD -> <re.Match object; span=(0, 6), match='select'> at position 0
2025-05-03 15:23:20,656 - compiler.tokenizer - DEBUG - ASTERISK -> <re.Match object; span=(7, 8), match='*'> at position 7
2025-05-03 15:23:20,656 - compiler.tokenizer - DEBUG - KEYWORD -> <re.Match object; span=(9, 13), match='from'> at position 9
2025-05-03 15:23:20,656 - compiler.tokenizer - DEBUG - IDENTIFIER -> <re.Match object; span=(14, 20), match='pinchu'> at position 14
2025-05-03 15:23:20,656 - compiler.tokenizer - ERROR - Invalid token at 20: @
2025-05-03 15:23:20,657 - __main__ - ERROR - Error: Invalid token at 20: @
2025-05-03 15:24:20,794 - compiler.tokenizer - ERROR - Invalid token at 0: &
2025-05-03 15:24:20,794 - __main__ - ERROR - Error: Invalid token at 0: &
2025-05-03 15:24:33,655 - compiler.tokenizer - DEBUG - KEYWORD -> <re.Match object; span=(0, 6), match='select'> at position 0
2025-05-03 15:24:33,656 - compiler.tokenizer - DEBUG - ASTERISK -> <re.Match object; span=(7, 8), match='*'> at position 7
2025-05-03 15:24:33,657 - compiler.tokenizer - DEBUG - KEYWORD -> <re.Match object; span=(9, 13), match='from'> at position 9
2025-05-03 15:24:33,657 - compiler.tokenizer - DEBUG - NUMBER -> <re.Match object; span=(14, 16), match='77'> at position 14
2025-05-03 15:24:33,657 - compiler.tokenizer - DEBUG - IDENTIFIER -> <re.Match object; span=(16, 22), match='kibund'> at position 16
2025-05-03 15:24:33,657 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD 
 
        value = SELECT) 
 
        position = 0, Token(type = ASTERISK 
 
        value = *) 
 
        position = 7, Token(type = KEYWORD 
 
        value = FROM) 
 
        position = 9, Token(type = NUMBER 
 
        value = 77) 
 
        position = 14, Token(type = IDENTIFIER 
 
        value = kibund) 
 
        position = 16]
2025-05-03 15:25:24,335 - compiler.tokenizer - DEBUG - KEYWORD -> <re.Match object; span=(0, 6), match='select'> at position 0
2025-05-03 15:25:24,336 - compiler.tokenizer - DEBUG - ASTERISK -> <re.Match object; span=(7, 8), match='*'> at position 7
2025-05-03 15:25:24,336 - compiler.tokenizer - DEBUG - KEYWORD -> <re.Match object; span=(9, 13), match='from'> at position 9
2025-05-03 15:25:24,336 - compiler.tokenizer - DEBUG - IDENTIFIER -> <re.Match object; span=(14, 20), match='pinchu'> at position 14
2025-05-03 15:25:24,336 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD,
        value = SELECT),
        position = 0, Token(type = ASTERISK,
        value = *),
        position = 7, Token(type = KEYWORD,
        value = FROM),
        position = 9, Token(type = IDENTIFIER,
        value = pinchu),
        position = 14]
2025-05-03 15:28:06,040 - compiler.tokenizer - DEBUG - Matched KEYWORD: 'SELECT' at position 0
2025-05-03 15:28:06,041 - compiler.tokenizer - DEBUG - Matched ASTERISK: '*' at position 7
2025-05-03 15:28:06,041 - compiler.tokenizer - DEBUG - Matched KEYWORD: 'FROM' at position 9
2025-05-03 15:28:06,041 - compiler.tokenizer - DEBUG - Matched IDENTIFIER: 'pinchiu' at position 14
2025-05-03 15:28:06,041 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = pinchiu), position = 14]
2025-05-03 15:28:52,558 - compiler.tokenizer - ERROR - Invalid token at 0: &
2025-05-03 15:28:52,558 - __main__ - ERROR - Error: Invalid token at 0: &
2025-05-03 15:29:00,771 - compiler.tokenizer - DEBUG - Matched IDENTIFIER: 'create' at position 0
2025-05-03 15:29:00,771 - compiler.tokenizer - DEBUG - Matched IDENTIFIER: 'table' at position 7
2025-05-03 15:29:00,771 - compiler.tokenizer - DEBUG - Matched IDENTIFIER: 'me' at position 13
2025-05-03 15:29:00,771 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = IDENTIFIER, value = create), position = 0, Token(type = IDENTIFIER, value = table), position = 7, Token(type = IDENTIFIER, value = me), position = 13]
2025-05-03 15:29:22,576 - compiler.tokenizer - DEBUG - Matched KEYWORD: 'SELECT' at position 0
2025-05-03 15:29:22,577 - compiler.tokenizer - DEBUG - Matched ASTERISK: '*' at position 7
2025-05-03 15:29:22,577 - compiler.tokenizer - DEBUG - Matched KEYWORD: 'FROM' at position 9
2025-05-03 15:29:22,578 - compiler.tokenizer - DEBUG - Matched IDENTIFIER: 'table' at position 14
2025-05-03 15:29:22,578 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = table), position = 14]
2025-05-03 16:47:24,034 - __main__ - INFO - 
Processing query: SELECT * FROM users
2025-05-03 16:47:24,035 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = users), position = 14]
2025-05-03 16:47:24,035 - __main__ - DEBUG - Tokens: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = users), position = 14]
2025-05-03 16:47:24,035 - __main__ - ERROR - Unexpected error: 'Token' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\main.py", line 23, in main
    word = parser.parse()
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 16, in parse
    return self.sql_statement()
           ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 37, in sql_statement
    if current and current[0] == "KEYWORD" and current[1] == "SELECT":
                   ~~~~~~~^^^
TypeError: 'Token' object is not subscriptable
2025-05-03 16:47:24,050 - __main__ - INFO - 
Processing query: SELECT name, age FROM employees
2025-05-03 16:47:24,050 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = IDENTIFIER, value = name), position = 7, Token(type = COMMA, value = ,), position = 11, Token(type = IDENTIFIER, value = age), position = 13, Token(type = KEYWORD, value = FROM), position = 17, Token(type = IDENTIFIER, value = employees), position = 22]
2025-05-03 16:47:24,050 - __main__ - DEBUG - Tokens: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = IDENTIFIER, value = name), position = 7, Token(type = COMMA, value = ,), position = 11, Token(type = IDENTIFIER, value = age), position = 13, Token(type = KEYWORD, value = FROM), position = 17, Token(type = IDENTIFIER, value = employees), position = 22]
2025-05-03 16:47:24,050 - __main__ - ERROR - Unexpected error: 'Token' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\main.py", line 23, in main
    word = parser.parse()
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 16, in parse
    return self.sql_statement()
           ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 37, in sql_statement
    if current and current[0] == "KEYWORD" and current[1] == "SELECT":
                   ~~~~~~~^^^
TypeError: 'Token' object is not subscriptable
2025-05-03 16:47:28,283 - __main__ - INFO - 
Processing query: SELECT * FROM users
2025-05-03 16:47:28,284 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = users), position = 14]
2025-05-03 16:47:28,284 - __main__ - DEBUG - Tokens: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = users), position = 14]
2025-05-03 16:47:28,284 - __main__ - ERROR - Unexpected error: 'Token' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\main.py", line 23, in main
    word = parser.parse()
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 16, in parse
    return self.sql_statement()
           ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 37, in sql_statement
    if current and current[0] == "KEYWORD" and current[1] == "SELECT":
                   ~~~~~~~^^^
TypeError: 'Token' object is not subscriptable
2025-05-03 16:47:28,292 - __main__ - INFO - 
Processing query: SELECT name, age FROM employees
2025-05-03 16:47:28,293 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = IDENTIFIER, value = name), position = 7, Token(type = COMMA, value = ,), position = 11, Token(type = IDENTIFIER, value = age), position = 13, Token(type = KEYWORD, value = FROM), position = 17, Token(type = IDENTIFIER, value = employees), position = 22]
2025-05-03 16:47:28,293 - __main__ - DEBUG - Tokens: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = IDENTIFIER, value = name), position = 7, Token(type = COMMA, value = ,), position = 11, Token(type = IDENTIFIER, value = age), position = 13, Token(type = KEYWORD, value = FROM), position = 17, Token(type = IDENTIFIER, value = employees), position = 22]
2025-05-03 16:47:28,293 - __main__ - ERROR - Unexpected error: 'Token' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\main.py", line 23, in main
    word = parser.parse()
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 16, in parse
    return self.sql_statement()
           ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 37, in sql_statement
    if current and current[0] == "KEYWORD" and current[1] == "SELECT":
                   ~~~~~~~^^^
TypeError: 'Token' object is not subscriptable
2025-05-03 16:48:53,647 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = pinchi), position = 14]
2025-05-03 16:48:53,647 - __main__ - DEBUG - Tokens: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = pinchi), position = 14]
2025-05-03 16:48:53,648 - __main__ - ERROR - Unexpected Error: 'Token' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\main.py", line 28, in main
    ast = parser.parse()
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 16, in parse
    return self.sql_statement()
           ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 37, in sql_statement
    if current and current[0] == "KEYWORD" and current[1] == "SELECT":
                   ~~~~~~~^^^
TypeError: 'Token' object is not subscriptable
2025-05-03 16:49:28,388 - compiler.tokenizer - ERROR - Invalid token at 20: ;
2025-05-03 16:49:28,389 - __main__ - ERROR - Tokenization Error: Invalid token at 20: ;
2025-05-03 16:49:33,223 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9]
2025-05-03 16:49:33,223 - __main__ - DEBUG - Tokens: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9]
2025-05-03 16:49:33,223 - __main__ - ERROR - Unexpected Error: 'Token' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\main.py", line 28, in main
    ast = parser.parse()
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 16, in parse
    return self.sql_statement()
           ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 37, in sql_statement
    if current and current[0] == "KEYWORD" and current[1] == "SELECT":
                   ~~~~~~~^^^
TypeError: 'Token' object is not subscriptable
2025-05-03 16:50:12,534 - compiler.tokenizer - ERROR - Invalid token at 0: &
2025-05-03 16:50:12,534 - __main__ - ERROR - Tokenization Error: Invalid token at 0: &
2025-05-03 16:50:21,085 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9]
2025-05-03 16:50:21,085 - __main__ - DEBUG - Tokens: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9]
2025-05-03 16:50:21,085 - __main__ - ERROR - Unexpected Error: 'Token' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\main.py", line 28, in main
    ast = parser.parse()
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 16, in parse
    return self.sql_statement()
           ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 37, in sql_statement
    if current and current[0] == "KEYWORD" and current[1] == "SELECT":
                   ~~~~~~~^^^
TypeError: 'Token' object is not subscriptable
2025-05-03 16:50:28,210 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = pinchu), position = 14]
2025-05-03 16:50:28,210 - __main__ - DEBUG - Tokens: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = pinchu), position = 14]
2025-05-03 16:50:28,210 - __main__ - ERROR - Unexpected Error: 'Token' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\main.py", line 28, in main
    ast = parser.parse()
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 16, in parse
    return self.sql_statement()
           ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 37, in sql_statement
    if current and current[0] == "KEYWORD" and current[1] == "SELECT":
                   ~~~~~~~^^^
TypeError: 'Token' object is not subscriptable
2025-05-03 16:53:40,212 - compiler.tokenizer - ERROR - Invalid token at 0: &
2025-05-03 16:53:40,212 - __main__ - ERROR - Tokenization Error: Invalid token at 0: &
2025-05-03 16:53:48,468 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = pinchu), position = 14]
2025-05-03 16:53:48,468 - __main__ - DEBUG - Tokens: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = pinchu), position = 14]
2025-05-03 16:53:48,468 - __main__ - ERROR - Unexpected Error: 'Token' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\main.py", line 28, in main
    ast = parser.parse()
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 16, in parse
    return self.sql_statement()
           ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 37, in sql_statement
    return self.select_statement()
               ^^^^^^^^^^
TypeError: 'Token' object is not subscriptable
2025-05-03 16:54:25,878 - compiler.tokenizer - ERROR - Invalid token at 0: &
2025-05-03 16:54:25,879 - __main__ - ERROR - Tokenization Error: Invalid token at 0: &
2025-05-03 16:54:31,997 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 6, Token(type = KEYWORD, value = FROM), position = 8, Token(type = IDENTIFIER, value = g), position = 13]
2025-05-03 16:54:31,997 - __main__ - DEBUG - Tokens: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 6, Token(type = KEYWORD, value = FROM), position = 8, Token(type = IDENTIFIER, value = g), position = 13]
2025-05-03 16:54:31,997 - __main__ - ERROR - Unexpected Error: 'Token' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\main.py", line 28, in main
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 16, in parse
    return self.sql_statement()
           ~~~~~~~~~~~~~~~~~~^^
  File "c:\Users\LAKSHAY JAIN\Downloads\CODING\DATA SCIENCE\SQLite Project\compiler\parser.py", line 37, in sql_statement
    return self.select_statement()
               ^^^^^^^^^^
TypeError: 'Token' object is not subscriptable
2025-05-03 16:54:37,492 - compiler.tokenizer - ERROR - Invalid token at 24: ;
2025-05-03 16:54:37,492 - compiler.tokenizer - ERROR - Invalid token at 39: ;
2025-05-03 16:54:37,492 - compiler.tokenizer - ERROR - Invalid token at 55: ;
2025-05-03 16:55:33,534 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = table_name), position = 14, Token(type = SEMICOLON, value = ;), position = 24]
2025-05-03 16:55:33,534 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 16:55:33,534 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT), position = 0
2025-05-03 16:55:33,534 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-03 16:55:33,534 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *), position = 7
2025-05-03 16:55:33,534 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM), position = 9
2025-05-03 16:55:33,534 - compiler.parser - DEBUG - Found table name: table_name
2025-05-03 16:55:33,534 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table_name), position = 14
2025-05-03 16:55:33,534 - compiler.parser - INFO - SELECT parsed: columns = ['*'] , table = table_name
2025-05-03 16:55:33,535 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = IDENTIFIER, value = column1), position = 7, Token(type = COMMA, value = ,), position = 14, Token(type = IDENTIFIER, value = column2), position = 16, Token(type = KEYWORD, value = FROM), position = 24, Token(type = IDENTIFIER, value = table_name), position = 29, Token(type = SEMICOLON, value = ;), position = 39]
2025-05-03 16:55:33,535 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 16:55:33,535 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT), position = 0
2025-05-03 16:55:33,535 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 16:55:33,535 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1), position = 7
2025-05-03 16:55:33,535 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,), position = 14
2025-05-03 16:55:33,535 - compiler.parser - DEBUG - Found Column: column2
2025-05-03 16:55:33,535 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column2), position = 16
2025-05-03 16:55:33,535 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM), position = 24
2025-05-03 16:55:33,535 - compiler.parser - DEBUG - Found table name: table_name
2025-05-03 16:55:33,535 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table_name), position = 29
2025-05-03 16:55:33,535 - compiler.parser - INFO - SELECT parsed: columns = ['column1', 'column2'] , table = table_name
2025-05-03 16:55:33,536 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT), position = 0, Token(type = KEYWORD, value = INTO), position = 7, Token(type = IDENTIFIER, value = table_name), position = 12, Token(type = KEYWORD, value = VALUES), position = 23, Token(type = LPAREN, value = (), position = 30, Token(type = QUOTE, value = '), position = 31, Token(type = IDENTIFIER, value = value1), position = 32, Token(type = QUOTE, value = '), position = 38, Token(type = COMMA, value = ,), position = 39, Token(type = NUMBER, value = 123), position = 41, Token(type = COMMA, value = ,), position = 44, Token(type = QUOTE, value = '), position = 46, Token(type = IDENTIFIER, value = value2), position = 47, Token(type = QUOTE, value = '), position = 53, Token(type = RPAREN, value = )), position = 54, Token(type = SEMICOLON, value = ;), position = 55]
2025-05-03 16:55:33,536 - compiler.parser - INFO - Parsing INSERT statement.
2025-05-03 16:55:33,536 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT), position = 0
2025-05-03 16:55:33,536 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO), position = 7
2025-05-03 16:55:33,536 - compiler.parser - DEBUG - Found table name: table_name
2025-05-03 16:55:33,536 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table_name), position = 12
2025-05-03 16:55:33,536 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES), position = 23
2025-05-03 16:55:33,536 - compiler.parser - ERROR - Expected at least one value in INSERT statement.
2025-05-03 16:55:41,408 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = table_name), position = 14, Token(type = SEMICOLON, value = ;), position = 24]
2025-05-03 16:55:41,409 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT), position = 0
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *), position = 7
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM), position = 9
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Found table name: table_name
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table_name), position = 14
2025-05-03 16:55:41,409 - compiler.parser - INFO - SELECT parsed: columns = ['*'] , table = table_name
2025-05-03 16:55:41,409 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = IDENTIFIER, value = column1), position = 7, Token(type = COMMA, value = ,), position = 14, Token(type = IDENTIFIER, value = column2), position = 16, Token(type = KEYWORD, value = FROM), position = 24, Token(type = IDENTIFIER, value = table_name), position = 29, Token(type = SEMICOLON, value = ;), position = 39]
2025-05-03 16:55:41,409 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT), position = 0
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1), position = 7
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,), position = 14
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Found Column: column2
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column2), position = 16
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM), position = 24
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Found table name: table_name
2025-05-03 16:55:41,409 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table_name), position = 29
2025-05-03 16:55:41,409 - compiler.parser - INFO - SELECT parsed: columns = ['column1', 'column2'] , table = table_name
2025-05-03 16:55:41,410 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT), position = 0, Token(type = KEYWORD, value = INTO), position = 7, Token(type = IDENTIFIER, value = table_name), position = 12, Token(type = KEYWORD, value = VALUES), position = 23, Token(type = LPAREN, value = (), position = 30, Token(type = QUOTE, value = '), position = 31, Token(type = IDENTIFIER, value = value1), position = 32, Token(type = QUOTE, value = '), position = 38, Token(type = COMMA, value = ,), position = 39, Token(type = NUMBER, value = 123), position = 41, Token(type = COMMA, value = ,), position = 44, Token(type = QUOTE, value = '), position = 46, Token(type = IDENTIFIER, value = value2), position = 47, Token(type = QUOTE, value = '), position = 53, Token(type = RPAREN, value = )), position = 54, Token(type = SEMICOLON, value = ;), position = 55]
2025-05-03 16:55:41,410 - compiler.parser - INFO - Parsing INSERT statement.
2025-05-03 16:55:41,410 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT), position = 0
2025-05-03 16:55:41,410 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO), position = 7
2025-05-03 16:55:41,410 - compiler.parser - DEBUG - Found table name: table_name
2025-05-03 16:55:41,410 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table_name), position = 12
2025-05-03 16:55:41,410 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES), position = 23
2025-05-03 16:55:41,410 - compiler.parser - ERROR - Expected at least one value in INSERT statement.
2025-05-03 16:58:49,553 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = table), position = 14]
2025-05-03 16:59:50,872 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT), position = 0, Token(type = ASTERISK, value = *), position = 7, Token(type = KEYWORD, value = FROM), position = 9, Token(type = IDENTIFIER, value = table), position = 14]
2025-05-03 17:00:17,915 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT), position = 0, Token(type = KEYWORD, value = INTO), position = 7, Token(type = IDENTIFIER, value = table), position = 12]
2025-05-03 17:07:32,142 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = table, position = 14), Token(type = SEMICOLON, value = ;, position = 19)]
2025-05-03 17:07:32,142 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:07:32,143 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:07:32,143 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-03 17:07:32,143 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-03 17:07:32,143 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-03 17:07:32,143 - compiler.parser - DEBUG - Found table name: table
2025-05-03 17:07:32,143 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table, position = 14)
2025-05-03 17:07:32,143 - compiler.parser - INFO - SELECT parsed: columns = ['*'], table = table
2025-05-03 17:08:33,547 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = table, position = 14), Token(type = COMMA, value = ,, position = 19)]
2025-05-03 17:08:33,548 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:08:33,548 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:08:33,548 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-03 17:08:33,548 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-03 17:08:33,548 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-03 17:08:33,548 - compiler.parser - DEBUG - Found table name: table
2025-05-03 17:08:33,548 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table, position = 14)
2025-05-03 17:08:33,548 - compiler.parser - INFO - SELECT parsed: columns = ['*'], table = table
2025-05-03 17:08:58,829 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = table, position = 14), Token(type = COMMA, value = ,, position = 20), Token(type = KEYWORD, value = INSERT, position = 22)]
2025-05-03 17:08:58,829 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:08:58,829 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:08:58,829 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-03 17:08:58,830 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-03 17:08:58,830 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-03 17:08:58,830 - compiler.parser - DEBUG - Found table name: table
2025-05-03 17:08:58,830 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table, position = 14)
2025-05-03 17:08:58,830 - compiler.parser - INFO - SELECT parsed: columns = ['*'], table = table
2025-05-03 17:10:40,373 - compiler.tokenizer - ERROR - Invalid token at 47: .
2025-05-03 17:11:05,223 - compiler.tokenizer - ERROR - Invalid token at 47: .
2025-05-03 17:11:26,841 - compiler.tokenizer - ERROR - Invalid token at 47: .
2025-05-03 17:12:09,819 - compiler.tokenizer - ERROR - Invalid token at 51: =
2025-05-03 17:13:00,569 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:13:00,570 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:13:00,570 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:13:00,570 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 17:13:00,570 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-03 17:13:00,570 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-03 17:13:00,570 - compiler.parser - DEBUG - Found table name: table1
2025-05-03 17:13:00,570 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table1, position = 20)
2025-05-03 17:13:00,570 - compiler.parser - INFO - SELECT parsed: columns = ['column1'], table = table1
2025-05-03 17:16:01,676 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:16:01,676 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:16:01,677 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:16:01,677 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 17:16:01,677 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-03 17:16:01,677 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-03 17:16:01,677 - compiler.parser - DEBUG - Found table name: table1
2025-05-03 17:16:01,677 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table1, position = 20)
2025-05-03 17:16:01,677 - compiler.parser - INFO - SELECT parsed: columns = ['column1'], table = table1
2025-05-03 17:23:35,616 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:23:35,616 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:23:35,616 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:23:35,616 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 17:23:35,616 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-03 17:23:35,616 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-03 17:24:36,071 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:24:36,071 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:24:36,071 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:24:36,071 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 17:24:36,071 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-03 17:24:36,071 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-03 17:25:19,108 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:25:19,108 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:25:19,109 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:25:19,109 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 17:25:19,109 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-03 17:25:19,109 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-03 17:27:19,609 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:27:56,731 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:28:11,351 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:28:11,351 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:28:11,352 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:28:11,352 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 17:28:11,352 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-03 17:28:11,352 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-03 17:29:37,523 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:30:48,959 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:30:48,959 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:30:48,959 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:30:48,959 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 17:30:48,959 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-03 17:30:48,959 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-03 17:30:48,959 - compiler.parser - DEBUG - Found table name: table1
2025-05-03 17:30:48,959 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table1, position = 20)
2025-05-03 17:30:48,960 - compiler.parser - INFO - SELECT parsed: columns = ['column1'], table = table1
2025-05-03 17:33:11,183 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:33:11,183 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:33:11,184 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:33:11,184 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 17:33:11,184 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-03 17:33:11,184 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-03 17:33:11,184 - compiler.parser - DEBUG - Found Table: table1
2025-05-03 17:33:11,184 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table1, position = 20)
2025-05-03 17:33:11,184 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 26)
2025-05-03 17:33:11,184 - compiler.parser - DEBUG - Found Table: table2
2025-05-03 17:33:11,184 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table2, position = 28)
2025-05-03 17:33:11,184 - compiler.parser - INFO - SELECT parsed: columns = ['column1'], tables = ['table1', 'table2']
2025-05-03 17:34:40,401 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:34:40,401 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:34:40,401 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:34:40,401 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 17:34:40,401 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-03 17:34:40,401 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-03 17:34:40,401 - compiler.parser - DEBUG - Found Table: table1
2025-05-03 17:34:40,401 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table1, position = 20)
2025-05-03 17:34:40,401 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 26)
2025-05-03 17:34:40,401 - compiler.parser - DEBUG - Found Table: table2
2025-05-03 17:34:40,401 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table2, position = 28)
2025-05-03 17:34:40,401 - compiler.parser - INFO - SELECT parsed: columns = ['column1'], tables = ['table1', 'table2']
2025-05-03 17:38:06,569 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:38:06,570 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:38:06,570 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:38:06,571 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 17:38:06,571 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-03 17:38:06,571 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-03 17:38:06,571 - compiler.parser - DEBUG - Found Table: table1
2025-05-03 17:38:06,571 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table1, position = 20)
2025-05-03 17:38:06,571 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 26)
2025-05-03 17:38:06,571 - compiler.parser - DEBUG - Found Table: table2
2025-05-03 17:38:06,571 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table2, position = 28)
2025-05-03 17:38:06,571 - compiler.parser - INFO - SELECT parsed: columns = ['column1'], tables = ['table1', 'table2']
2025-05-03 17:38:39,066 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:38:39,068 - compiler.parser - INFO - Parsing SELECT statement
2025-05-03 17:38:39,068 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-03 17:38:39,068 - compiler.parser - DEBUG - Found Column: column1
2025-05-03 17:38:39,068 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-03 17:38:39,068 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-03 17:38:39,068 - compiler.parser - DEBUG - Found Table: table1
2025-05-03 17:38:39,068 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table1, position = 20)
2025-05-03 17:38:39,068 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 26)
2025-05-03 17:38:39,068 - compiler.parser - DEBUG - Found Table: table2
2025-05-03 17:38:39,068 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table2, position = 28)
2025-05-03 17:38:39,068 - compiler.parser - INFO - SELECT parsed: columns = ['column1'], tables = ['table1', 'table2']
2025-05-03 17:38:57,597 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-03 17:38:57,598 - compiler.parser - INFO - Parsing INSERT statement.
2025-05-03 17:38:57,598 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-03 17:38:57,598 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-03 17:38:57,598 - compiler.parser - ERROR - Expected a table name..
2025-05-03 17:39:37,986 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = IDENTIFIER, value = create, position = 0), Token(type = IDENTIFIER, value = table, position = 7), Token(type = IDENTIFIER, value = huni, position = 13)]
2025-05-03 17:39:37,986 - compiler.parser - ERROR - Invalid SQL statement found: Token(type = IDENTIFIER, value = create, position = 0)
2025-05-04 02:51:42,067 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = table, position = 14)]
2025-05-04 02:51:42,068 - compiler.parser - INFO - Parsing SELECT statement
2025-05-04 02:51:42,068 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 02:51:42,068 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-04 02:51:42,068 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-04 02:51:42,068 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-04 02:51:42,068 - compiler.parser - DEBUG - Found Table: table
2025-05-04 02:51:42,068 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table, position = 14)
2025-05-04 02:51:42,068 - compiler.parser - INFO - SELECT parsed: columns = ['*'], tables = ['table']
2025-05-04 03:31:30,207 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = pinchi, position = 14)]
2025-05-04 03:31:30,207 - compiler.parser - INFO - Parsing SELECT statement
2025-05-04 03:31:30,207 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 03:31:30,207 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-04 03:31:30,207 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-04 03:31:30,207 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-04 03:31:30,207 - compiler.parser - DEBUG - Found Table: pinchi
2025-05-04 03:31:30,208 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = pinchi, position = 14)
2025-05-04 03:31:30,208 - compiler.parser - INFO - SELECT parsed: columns = ['*'], tables = ['pinchi']
2025-05-04 03:31:51,726 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = IDENTIFIER, value = fetch, position = 0), Token(type = ASTERISK, value = *, position = 6), Token(type = KEYWORD, value = FROM, position = 8), Token(type = IDENTIFIER, value = sasnkar, position = 13)]
2025-05-04 03:31:51,726 - compiler.parser - ERROR - Invalid SQL statement found: Token(type = IDENTIFIER, value = fetch, position = 0)
2025-05-04 03:32:16,404 - compiler.tokenizer - ERROR - Invalid token at 18: @
2025-05-04 03:33:55,910 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-04 03:33:55,911 - compiler.parser - INFO - Parsing INSERT statement.
2025-05-04 03:33:55,911 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-04 03:33:55,911 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-04 03:33:55,911 - compiler.parser - ERROR - Expected a table name..
2025-05-04 03:34:23,765 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-04 03:34:23,767 - compiler.parser - INFO - Parsing INSERT statement.
2025-05-04 03:34:23,767 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-04 03:34:23,767 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-04 03:34:23,767 - compiler.parser - ERROR - Expected a table name..
2025-05-04 03:34:57,430 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-04 03:34:57,431 - compiler.parser - INFO - Parsing INSERT statement.
2025-05-04 03:34:57,431 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-04 03:34:57,431 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-04 03:34:57,431 - compiler.parser - ERROR - Expected a table name..
2025-05-04 03:36:05,630 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = column1, position = 12), Token(type = KEYWORD, value = FROM, position = 20), Token(type = IDENTIFIER, value = table1, position = 25), Token(type = COMMA, value = ,, position = 31), Token(type = IDENTIFIER, value = table2, position = 33), Token(type = IDENTIFIER, value = where, position = 40), Token(type = IDENTIFIER, value = table1, position = 46), Token(type = DOT, value = ., position = 52), Token(type = IDENTIFIER, value = id, position = 53), Token(type = EQUALS, value = =, position = 56), Token(type = IDENTIFIER, value = table2, position = 58), Token(type = DOT, value = ., position = 64), Token(type = IDENTIFIER, value = id, position = 65), Token(type = SEMICOLON, value = ;, position = 67)]
2025-05-04 03:36:05,631 - compiler.parser - INFO - Parsing INSERT statement.
2025-05-04 03:36:05,631 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-04 03:36:05,631 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-04 03:36:05,631 - compiler.parser - DEBUG - Found table name: column1
2025-05-04 03:36:05,631 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 12)

2025-05-04 03:36:05,631 - compiler.parser - ERROR - Expected 'VALUES' in INSERT statement.
2025-05-04 03:36:18,397 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = table1, position = 20), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = table2, position = 28), Token(type = IDENTIFIER, value = where, position = 35), Token(type = IDENTIFIER, value = table1, position = 41), Token(type = DOT, value = ., position = 47), Token(type = IDENTIFIER, value = id, position = 48), Token(type = EQUALS, value = =, position = 51), Token(type = IDENTIFIER, value = table2, position = 53), Token(type = DOT, value = ., position = 59), Token(type = IDENTIFIER, value = id, position = 60), Token(type = SEMICOLON, value = ;, position = 62)]
2025-05-04 03:36:18,397 - compiler.parser - INFO - Parsing SELECT statement
2025-05-04 03:36:18,397 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 03:36:18,398 - compiler.parser - DEBUG - Found Column: column1
2025-05-04 03:36:18,398 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-04 03:36:18,398 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-04 03:36:18,398 - compiler.parser - DEBUG - Found Table: table1
2025-05-04 03:36:18,398 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table1, position = 20)
2025-05-04 03:36:18,398 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 26)
2025-05-04 03:36:18,398 - compiler.parser - DEBUG - Found Table: table2
2025-05-04 03:36:18,398 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table2, position = 28)
2025-05-04 03:36:18,398 - compiler.parser - INFO - SELECT parsed: columns = ['column1'], tables = ['table1', 'table2']
2025-05-04 03:36:59,816 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = table1, position = 14), Token(type = COMMA, value = ,, position = 20), Token(type = IDENTIFIER, value = table2, position = 22), Token(type = IDENTIFIER, value = where, position = 29), Token(type = IDENTIFIER, value = table1, position = 35), Token(type = DOT, value = ., position = 41), Token(type = IDENTIFIER, value = id, position = 42), Token(type = EQUALS, value = =, position = 45), Token(type = IDENTIFIER, value = table2, position = 47), Token(type = DOT, value = ., position = 53), Token(type = IDENTIFIER, value = id, position = 54), Token(type = SEMICOLON, value = ;, position = 56)]
2025-05-04 03:36:59,817 - compiler.parser - INFO - Parsing SELECT statement
2025-05-04 03:36:59,817 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 03:36:59,817 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-04 03:36:59,817 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-04 03:36:59,817 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-04 03:36:59,817 - compiler.parser - DEBUG - Found Table: table1
2025-05-04 03:36:59,817 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table1, position = 14)
2025-05-04 03:36:59,817 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 20)
2025-05-04 03:36:59,817 - compiler.parser - DEBUG - Found Table: table2
2025-05-04 03:36:59,817 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table2, position = 22)
2025-05-04 03:36:59,817 - compiler.parser - INFO - SELECT parsed: columns = ['*'], tables = ['table1', 'table2']
2025-05-04 04:23:11,318 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = IDENTIFIER, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = IDENTIFIER, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799, position = 28), Token(type = DOT, value = ., position = 31), Token(type = NUMBER, value = 99, position = 32), Token(type = IDENTIFIER, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 04:23:11,318 - compiler.parser - ERROR - Invalid SQL statement: Token(type = IDENTIFIER, value = UPDATE, position = 0)
2025-05-04 04:25:36,265 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799.99, position = 28), Token(type = KEYWORD, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 04:25:36,266 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-04 04:25:36,266 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-04 04:25:36,266 - compiler.parser - DEBUG - Found table name: products
2025-05-04 04:25:36,266 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-04 04:25:36,266 - compiler.statements.update_parser - DEBUG - UPDATE table: products
2025-05-04 04:25:36,266 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-04 04:26:59,669 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799.99, position = 28), Token(type = KEYWORD, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 04:26:59,670 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-04 04:26:59,670 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-04 04:26:59,670 - compiler.parser - DEBUG - Found table name: products
2025-05-04 04:26:59,670 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-04 04:26:59,670 - compiler.statements.update_parser - DEBUG - UPDATE table: products
2025-05-04 04:26:59,670 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-04 04:29:14,799 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799.99, position = 28), Token(type = KEYWORD, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 04:29:14,800 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-04 04:29:14,800 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-04 04:29:14,800 - compiler.parser - DEBUG - Found table name: products
2025-05-04 04:29:14,800 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-04 04:29:14,800 - compiler.statements.update_parser - DEBUG - UPDATE table: products
2025-05-04 04:29:14,800 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-04 04:29:14,800 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = price, position = 20)
2025-05-04 04:29:14,800 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 26)
2025-05-04 04:29:14,800 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 799.99, position = 28)
2025-05-04 04:29:14,800 - compiler.statements.update_parser - DEBUG - SET clause: [('price', '799.99')]
2025-05-04 04:29:14,800 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 35)
2025-05-04 04:33:25,139 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799.99, position = 28), Token(type = KEYWORD, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 04:33:25,140 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-04 04:33:25,140 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-04 04:33:25,140 - compiler.parser - DEBUG - Found table name: products
2025-05-04 04:33:25,140 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-04 04:33:25,141 - compiler.statements.update_parser - DEBUG - UPDATE table: products
2025-05-04 04:33:25,141 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-04 04:33:25,141 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = price, position = 20)
2025-05-04 04:33:25,141 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 26)
2025-05-04 04:33:25,141 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 799.99, position = 28)
2025-05-04 04:33:25,141 - compiler.statements.update_parser - DEBUG - SET clause: [('price', '799.99')]
2025-05-04 04:33:25,141 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 35)
2025-05-04 04:34:31,481 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = WHERE, position = 16), Token(type = IDENTIFIER, value = id, position = 22), Token(type = EQUALS, value = =, position = 25), Token(type = NUMBER, value = 5, position = 27), Token(type = SEMICOLON, value = ;, position = 28)]
2025-05-04 04:34:31,481 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 04:36:54,541 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = WHERE, position = 16), Token(type = IDENTIFIER, value = id, position = 22), Token(type = EQUALS, value = =, position = 25), Token(type = NUMBER, value = 5, position = 27), Token(type = SEMICOLON, value = ;, position = 28)]
2025-05-04 04:36:54,542 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 04:36:54,542 - compiler.parser - DEBUG - Found Column: products
2025-05-04 04:36:54,542 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-04 04:36:54,542 - compiler.statements.select_parser - ERROR - Expected 'FROM' in SELECT statement.
2025-05-04 04:37:07,358 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = products, position = 12), Token(type = KEYWORD, value = WHERE, position = 21), Token(type = IDENTIFIER, value = id, position = 27), Token(type = EQUALS, value = =, position = 30), Token(type = NUMBER, value = 5, position = 32), Token(type = SEMICOLON, value = ;, position = 33)]
2025-05-04 04:37:07,359 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 04:37:07,359 - compiler.parser - ERROR - Expected at least one column in SELECT statement.
2025-05-04 04:37:21,772 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column2, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = products, position = 20), Token(type = KEYWORD, value = WHERE, position = 29), Token(type = IDENTIFIER, value = id, position = 35), Token(type = EQUALS, value = =, position = 38), Token(type = NUMBER, value = 5, position = 40), Token(type = SEMICOLON, value = ;, position = 41)]
2025-05-04 04:37:21,773 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 04:37:21,773 - compiler.parser - DEBUG - Found Column: column2
2025-05-04 04:37:21,773 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column2, position = 7)
2025-05-04 04:37:21,773 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-04 04:40:26,443 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column2, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = products, position = 20), Token(type = KEYWORD, value = WHERE, position = 29), Token(type = IDENTIFIER, value = id, position = 35), Token(type = EQUALS, value = =, position = 38), Token(type = NUMBER, value = 5, position = 40), Token(type = SEMICOLON, value = ;, position = 41)]
2025-05-04 04:40:26,443 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 04:40:26,443 - compiler.parser - DEBUG - Found Column: column2
2025-05-04 04:40:26,444 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column2, position = 7)
2025-05-04 04:40:26,444 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-04 04:40:38,947 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column2, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = products, position = 20), Token(type = SEMICOLON, value = ;, position = 28)]
2025-05-04 04:40:38,948 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 04:40:38,948 - compiler.parser - DEBUG - Found Column: column2
2025-05-04 04:40:38,948 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column2, position = 7)
2025-05-04 04:40:38,948 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-04 04:41:02,439 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column2, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = products, position = 20), Token(type = SEMICOLON, value = ;, position = 28)]
2025-05-04 04:41:02,440 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 04:41:02,440 - compiler.parser - DEBUG - Found Column: column2
2025-05-04 04:41:02,440 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column2, position = 7)
2025-05-04 04:41:02,440 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-04 04:41:02,440 - compiler.parser - DEBUG - Found Table: products
2025-05-04 04:41:02,440 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 20)
2025-05-04 04:41:02,440 - compiler.statements.select_parser - INFO - SELECT parsed: columns = ['column2'], tables = ['products']
2025-05-04 04:41:08,951 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column2, position = 7), Token(type = KEYWORD, value = FROM, position = 15), Token(type = IDENTIFIER, value = products, position = 20), Token(type = KEYWORD, value = WHERE, position = 29), Token(type = IDENTIFIER, value = id, position = 35), Token(type = EQUALS, value = =, position = 38), Token(type = NUMBER, value = 5, position = 40), Token(type = SEMICOLON, value = ;, position = 41)]
2025-05-04 04:41:08,952 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 04:41:08,952 - compiler.parser - DEBUG - Found Column: column2
2025-05-04 04:41:08,952 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column2, position = 7)
2025-05-04 04:41:08,952 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 15)
2025-05-04 04:41:08,952 - compiler.parser - DEBUG - Found Table: products
2025-05-04 04:41:08,952 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 20)
2025-05-04 04:41:08,952 - compiler.statements.select_parser - INFO - SELECT parsed: columns = ['column2'], tables = ['products']
2025-05-04 04:42:09,521 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799.99, position = 28), Token(type = KEYWORD, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 04:42:09,522 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-04 04:42:09,522 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-04 04:42:09,522 - compiler.parser - DEBUG - Found table name: products
2025-05-04 04:42:09,522 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-04 04:42:09,522 - compiler.statements.update_parser - DEBUG - UPDATE table: products
2025-05-04 04:42:09,523 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-04 04:42:09,523 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = price, position = 20)
2025-05-04 04:42:09,523 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 26)
2025-05-04 04:42:09,523 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 799.99, position = 28)
2025-05-04 04:42:09,523 - compiler.statements.update_parser - DEBUG - SET clause: [('price', '799.99')]
2025-05-04 04:42:09,523 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 35)
2025-05-04 04:42:09,523 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 41)
2025-05-04 04:42:09,523 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 44)
2025-05-04 04:42:09,523 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 5, position = 46)
2025-05-04 04:42:09,523 - compiler.statements.update_parser - DEBUG - WHERE condition: {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 04:42:09,523 - compiler.statements.update_parser - INFO - UPDATE parsed: table = products, SET = [('price', '799.99')], WHERE = {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 15:48:12,670 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799.99, position = 28), Token(type = KEYWORD, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 15:48:12,670 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-04 15:48:12,671 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-04 15:48:12,671 - compiler.parser - DEBUG - Found table name: products
2025-05-04 15:48:12,671 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-04 15:48:12,671 - compiler.statements.update_parser - DEBUG - UPDATE table: products
2025-05-04 15:48:12,671 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-04 15:48:12,671 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = price, position = 20)
2025-05-04 15:48:12,671 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 26)
2025-05-04 15:48:12,671 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 799.99, position = 28)
2025-05-04 15:48:12,671 - compiler.statements.update_parser - DEBUG - SET clause: [('price', '799.99')]
2025-05-04 15:48:12,671 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 35)
2025-05-04 15:48:12,671 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 41)
2025-05-04 15:48:12,671 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 44)
2025-05-04 15:48:12,671 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 5, position = 46)
2025-05-04 15:48:12,671 - compiler.statements.update_parser - DEBUG - WHERE condition: {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 15:48:12,671 - compiler.statements.update_parser - INFO - UPDATE parsed: table = products, SET = [('price', '799.99')], WHERE = {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 15:59:49,933 - compiler.tokenizer - ERROR - Invalid token at 0: &
2025-05-04 20:39:52,957 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799.99, position = 28), Token(type = KEYWORD, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 20:39:52,958 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-04 20:39:52,958 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-04 20:39:52,959 - compiler.parser - DEBUG - Found table name: products
2025-05-04 20:39:52,959 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-04 20:39:52,959 - compiler.statements.update_parser - DEBUG - UPDATE table: products
2025-05-04 20:39:52,959 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-04 20:39:52,959 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = price, position = 20)
2025-05-04 20:39:52,959 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 26)
2025-05-04 20:39:52,959 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 799.99, position = 28)
2025-05-04 20:39:52,959 - compiler.statements.update_parser - DEBUG - SET clause: [('price', '799.99')]
2025-05-04 20:39:52,959 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 35)
2025-05-04 20:39:52,959 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 41)
2025-05-04 20:39:52,959 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 44)
2025-05-04 20:39:52,959 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 5, position = 46)
2025-05-04 20:39:52,959 - compiler.statements.update_parser - DEBUG - WHERE condition: {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 20:39:52,960 - compiler.statements.update_parser - INFO - UPDATE parsed: table = products, SET = [('price', '799.99')], WHERE = {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 20:46:01,092 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799.99, position = 28), Token(type = KEYWORD, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 20:48:07,538 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799.99, position = 28), Token(type = KEYWORD, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 20:48:07,539 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-04 20:48:07,539 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-04 20:48:07,539 - compiler.parser - DEBUG - Found table name: products
2025-05-04 20:48:07,539 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-04 20:48:07,539 - compiler.statements.update_parser - DEBUG - UPDATE table: products
2025-05-04 20:48:07,539 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-04 20:48:07,539 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = price, position = 20)
2025-05-04 20:48:07,539 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 26)
2025-05-04 20:48:07,539 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 799.99, position = 28)
2025-05-04 20:48:07,540 - compiler.statements.update_parser - DEBUG - SET clause: [('price', '799.99')]
2025-05-04 20:48:07,540 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 35)
2025-05-04 20:48:07,540 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 41)
2025-05-04 20:48:07,540 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 44)
2025-05-04 20:48:07,540 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 5, position = 46)
2025-05-04 20:48:07,540 - compiler.statements.update_parser - DEBUG - WHERE condition: {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 20:48:07,540 - compiler.statements.update_parser - INFO - UPDATE parsed: table = products, SET = [('price', '799.99')], WHERE = {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 20:53:33,633 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799.99, position = 28), Token(type = KEYWORD, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 20:53:33,634 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-04 20:53:33,634 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-04 20:53:33,634 - compiler.parser - DEBUG - Found table name: products
2025-05-04 20:53:33,634 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-04 20:53:33,634 - compiler.statements.update_parser - DEBUG - UPDATE table: products
2025-05-04 20:53:33,634 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-04 20:53:33,635 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = price, position = 20)
2025-05-04 20:53:33,635 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 26)
2025-05-04 20:53:33,635 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 799.99, position = 28)
2025-05-04 20:53:33,635 - compiler.statements.update_parser - DEBUG - SET clause: [('price', '799.99')]
2025-05-04 20:53:33,635 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 35)
2025-05-04 20:53:33,635 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 41)
2025-05-04 20:53:33,635 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 44)
2025-05-04 20:53:33,635 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 5, position = 46)
2025-05-04 20:53:33,635 - compiler.statements.update_parser - DEBUG - WHERE condition: {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 20:53:33,635 - compiler.statements.update_parser - INFO - UPDATE parsed: table = products, SET = [('price', '799.99')], WHERE = {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 21:24:56,852 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799.99, position = 28), Token(type = KEYWORD, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 21:24:56,856 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-04 21:24:56,856 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-04 21:24:56,856 - compiler.parser - DEBUG - Found table name: products
2025-05-04 21:24:56,856 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-04 21:24:56,856 - compiler.statements.update_parser - DEBUG - UPDATE table: products
2025-05-04 21:24:56,856 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-04 21:24:56,856 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = price, position = 20)
2025-05-04 21:24:56,856 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 26)
2025-05-04 21:24:56,858 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 799.99, position = 28)
2025-05-04 21:24:56,858 - compiler.statements.update_parser - DEBUG - SET clause: [('price', '799.99')]
2025-05-04 21:24:56,858 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 35)
2025-05-04 21:24:56,858 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 41)
2025-05-04 21:24:56,858 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 44)
2025-05-04 21:24:56,858 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 5, position = 46)
2025-05-04 21:24:56,858 - compiler.statements.update_parser - DEBUG - WHERE condition: {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 21:24:56,858 - compiler.statements.update_parser - INFO - UPDATE parsed: table = products, SET = [('price', '799.99')], WHERE = {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 21:31:44,503 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 799.99, position = 28), Token(type = KEYWORD, value = WHERE, position = 35), Token(type = IDENTIFIER, value = id, position = 41), Token(type = EQUALS, value = =, position = 44), Token(type = NUMBER, value = 5, position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-04 21:31:44,507 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-04 21:31:44,507 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-04 21:31:44,507 - compiler.parser - DEBUG - Found table name: products
2025-05-04 21:31:44,507 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-04 21:31:44,507 - compiler.statements.update_parser - DEBUG - UPDATE table: products
2025-05-04 21:31:44,507 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-04 21:31:44,507 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = price, position = 20)
2025-05-04 21:31:44,507 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 26)
2025-05-04 21:31:44,507 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 799.99, position = 28)
2025-05-04 21:31:44,507 - compiler.statements.update_parser - DEBUG - SET clause: [('price', '799.99')]
2025-05-04 21:31:44,507 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 35)
2025-05-04 21:31:44,507 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 41)
2025-05-04 21:31:44,507 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 44)
2025-05-04 21:31:44,507 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 5, position = 46)
2025-05-04 21:31:44,507 - compiler.statements.update_parser - DEBUG - WHERE condition: {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 21:31:44,507 - compiler.statements.update_parser - INFO - UPDATE parsed: table = products, SET = [('price', '799.99')], WHERE = {'column': 'id', 'operator': '=', 'value': '5'}
2025-05-04 21:32:49,271 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = KEYWORD, value = TABLE, position = 12)]
2025-05-04 21:32:49,274 - compiler.statements.insert_parser - INFO - Parsing INSERT statement...
2025-05-04 21:32:49,274 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-04 21:32:49,274 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-04 21:32:49,274 - compiler.parser - ERROR - Expected a table name..
2025-05-04 21:34:34,916 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = pinchu, position = 14)]
2025-05-04 21:34:34,919 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-04 21:34:34,919 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-04 21:34:34,919 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-04 21:34:34,919 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-04 21:34:34,919 - compiler.parser - DEBUG - Found Table: pinchu
2025-05-04 21:34:34,920 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = pinchu, position = 14)
2025-05-04 21:34:34,920 - compiler.statements.select_parser - INFO - SELECT parsed: columns = ['*'], tables = ['pinchu']
2025-05-05 02:21:04,898 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = marvel, position = 14)]
2025-05-05 02:21:04,910 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 02:21:04,910 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-05 02:21:04,910 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-05 02:21:04,910 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-05 02:21:04,910 - compiler.parser - DEBUG - Found Table: marvel
2025-05-05 02:21:04,910 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = marvel, position = 14)
2025-05-05 02:21:04,911 - compiler.statements.select_parser - INFO - SELECT parsed: columns = ['*'], tables = ['marvel']
2025-05-05 02:23:16,873 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = marvel, position = 14)]
2025-05-05 02:23:16,876 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 02:23:16,876 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-05 02:23:16,876 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-05 02:23:16,876 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-05 02:23:16,876 - compiler.parser - DEBUG - Found Table: marvel
2025-05-05 02:23:16,876 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = marvel, position = 14)
2025-05-05 02:23:16,876 - compiler.statements.select_parser - INFO - SELECT parsed: columns = ['*'], tables = ['marvel']
2025-05-05 02:24:36,811 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = VALUES, position = 18), Token(type = LPAREN, value = (, position = 25), Token(type = NUMBER, value = 1, position = 26), Token(type = COMMA, value = ,, position = 27), Token(type = QUOTE, value = ', position = 29), Token(type = IDENTIFIER, value = John, position = 30), Token(type = QUOTE, value = ', position = 34), Token(type = RPAREN, value = ), position = 35), Token(type = SEMICOLON, value = ;, position = 36)]
2025-05-05 02:24:36,815 - compiler.statements.insert_parser - INFO - Parsing INSERT statement...
2025-05-05 02:24:36,815 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 02:24:36,815 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 02:24:36,816 - compiler.parser - DEBUG - Found table name: users
2025-05-05 02:24:36,816 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 02:24:36,816 - compiler.statements.insert_parser - DEBUG - INSERT INTO: users
2025-05-05 02:24:36,816 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 18)
2025-05-05 02:24:36,816 - compiler.parser - ERROR - Expected at least one value in INSERT statement.
2025-05-05 02:26:00,069 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = column1, position = 7), Token(type = COMMA, value = ,, position = 15), Token(type = IDENTIFIER, value = column2, position = 17), Token(type = KEYWORD, value = FROM, position = 25), Token(type = IDENTIFIER, value = tables, position = 30)]
2025-05-05 02:26:00,071 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 02:26:00,071 - compiler.parser - DEBUG - Found Column: column1
2025-05-05 02:26:00,071 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column1, position = 7)
2025-05-05 02:26:00,071 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 15)
2025-05-05 02:26:00,071 - compiler.parser - DEBUG - Found Column: column2
2025-05-05 02:26:00,071 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = column2, position = 17)
2025-05-05 02:26:00,071 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 25)
2025-05-05 02:26:00,071 - compiler.parser - DEBUG - Found Table: tables
2025-05-05 02:26:00,071 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = tables, position = 30)
2025-05-05 02:26:00,071 - compiler.statements.select_parser - INFO - SELECT parsed: columns = ['column1', 'column2'], tables = ['tables']
2025-05-05 02:43:39,142 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = table_name, position = 12)]
2025-05-05 02:43:39,143 - compiler.statements.insert_parser - INFO - Parsing INSERT statement...
2025-05-05 02:43:39,145 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 02:43:39,145 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 02:43:39,145 - compiler.parser - DEBUG - Found table name: table_name
2025-05-05 02:43:39,145 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table_name, position = 12)
2025-05-05 02:43:39,145 - compiler.statements.insert_parser - DEBUG - INSERT INTO: table_name
2025-05-05 02:44:09,721 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = table_name, position = 12), Token(type = KEYWORD, value = VALUES, position = 23), Token(type = LPAREN, value = (, position = 30), Token(type = IDENTIFIER, value = value1, position = 31), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = value2, position = 39), Token(type = COMMA, value = ,, position = 45), Token(type = IDENTIFIER, value = value3, position = 47), Token(type = RPAREN, value = ), position = 53), Token(type = SEMICOLON, value = ;, position = 54)]
2025-05-05 02:44:09,725 - compiler.statements.insert_parser - INFO - Parsing INSERT statement...
2025-05-05 02:44:09,725 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 02:44:09,725 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 02:44:09,725 - compiler.parser - DEBUG - Found table name: table_name
2025-05-05 02:44:09,725 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table_name, position = 12)
2025-05-05 02:44:09,725 - compiler.statements.insert_parser - DEBUG - INSERT INTO: table_name
2025-05-05 02:44:09,725 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 23)
2025-05-05 02:44:09,725 - compiler.parser - ERROR - Expected at least one value in INSERT statement.
2025-05-05 02:44:24,213 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = table_name, position = 12), Token(type = KEYWORD, value = VALUES, position = 23), Token(type = IDENTIFIER, value = value1, position = 30), Token(type = SEMICOLON, value = ;, position = 36)]
2025-05-05 02:44:24,213 - compiler.statements.insert_parser - INFO - Parsing INSERT statement...
2025-05-05 02:44:24,213 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 02:44:24,213 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 02:44:24,213 - compiler.parser - DEBUG - Found table name: table_name
2025-05-05 02:44:24,213 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table_name, position = 12)
2025-05-05 02:44:24,216 - compiler.statements.insert_parser - DEBUG - INSERT INTO: table_name
2025-05-05 02:44:24,216 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 23)
2025-05-05 02:44:24,216 - compiler.parser - ERROR - Expected at least one value in INSERT statement.
2025-05-05 02:47:50,452 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = table_name, position = 12), Token(type = KEYWORD, value = VALUES, position = 23), Token(type = LPAREN, value = (, position = 30), Token(type = IDENTIFIER, value = value1, position = 31), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = value2, position = 39), Token(type = COMMA, value = ,, position = 45), Token(type = IDENTIFIER, value = value3, position = 47), Token(type = RPAREN, value = ), position = 53), Token(type = SEMICOLON, value = ;, position = 54)]
2025-05-05 02:50:39,076 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = table_name, position = 12), Token(type = KEYWORD, value = VALUES, position = 23), Token(type = LPAREN, value = (, position = 30), Token(type = IDENTIFIER, value = value1, position = 31), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = value2, position = 39), Token(type = COMMA, value = ,, position = 45), Token(type = IDENTIFIER, value = value3, position = 47), Token(type = RPAREN, value = ), position = 53), Token(type = SEMICOLON, value = ;, position = 54)]
2025-05-05 02:52:14,852 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = table_name, position = 12), Token(type = KEYWORD, value = VALUES, position = 23), Token(type = LPAREN, value = (, position = 30), Token(type = IDENTIFIER, value = value1, position = 31), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = value2, position = 39), Token(type = COMMA, value = ,, position = 45), Token(type = IDENTIFIER, value = value3, position = 47), Token(type = RPAREN, value = ), position = 53), Token(type = SEMICOLON, value = ;, position = 54)]
2025-05-05 02:53:25,540 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = table_name, position = 12), Token(type = KEYWORD, value = VALUES, position = 23), Token(type = LPAREN, value = (, position = 30), Token(type = IDENTIFIER, value = value1, position = 31), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = value2, position = 39), Token(type = COMMA, value = ,, position = 45), Token(type = IDENTIFIER, value = value3, position = 47), Token(type = RPAREN, value = ), position = 53), Token(type = SEMICOLON, value = ;, position = 54)]
2025-05-05 02:54:32,978 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = table_name, position = 12), Token(type = KEYWORD, value = VALUES, position = 23), Token(type = LPAREN, value = (, position = 30), Token(type = IDENTIFIER, value = value1, position = 31), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = value2, position = 39), Token(type = COMMA, value = ,, position = 45), Token(type = IDENTIFIER, value = value3, position = 47), Token(type = RPAREN, value = ), position = 53), Token(type = SEMICOLON, value = ;, position = 54)]
2025-05-05 02:54:55,343 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = table_name, position = 12), Token(type = KEYWORD, value = VALUES, position = 23), Token(type = LPAREN, value = (, position = 30), Token(type = IDENTIFIER, value = value1, position = 31), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = value2, position = 39), Token(type = COMMA, value = ,, position = 45), Token(type = IDENTIFIER, value = value3, position = 47), Token(type = RPAREN, value = ), position = 53), Token(type = SEMICOLON, value = ;, position = 54)]
2025-05-05 02:54:55,348 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 02:54:55,348 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 02:54:55,349 - compiler.parser - DEBUG - Found table name: table_name
2025-05-05 02:54:55,349 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = table_name, position = 12)
2025-05-05 02:54:55,349 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 23)
2025-05-05 02:54:55,349 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 30)
2025-05-05 02:54:55,349 - compiler.parser - ERROR - Expected at least one value in INSERT statement.
2025-05-05 02:55:34,664 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = VALUES, position = 18), Token(type = LPAREN, value = (, position = 25), Token(type = NUMBER, value = 1, position = 26), Token(type = COMMA, value = ,, position = 27), Token(type = QUOTE, value = ', position = 29), Token(type = IDENTIFIER, value = John, position = 30), Token(type = QUOTE, value = ', position = 34), Token(type = RPAREN, value = ), position = 35), Token(type = SEMICOLON, value = ;, position = 36)]
2025-05-05 02:55:34,673 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 02:55:34,673 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 02:55:34,673 - compiler.parser - DEBUG - Found table name: users
2025-05-05 02:55:34,673 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 02:55:34,673 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 18)
2025-05-05 02:55:34,673 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 25)
2025-05-05 02:55:34,673 - compiler.parser - DEBUG - Found value: 1
2025-05-05 02:55:34,673 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 26)
2025-05-05 02:55:34,673 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 27)
2025-05-05 02:55:45,179 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = VALUES, position = 18), Token(type = LPAREN, value = (, position = 25), Token(type = NUMBER, value = 1, position = 26), Token(type = COMMA, value = ,, position = 27), Token(type = QUOTE, value = ', position = 29), Token(type = IDENTIFIER, value = John, position = 30), Token(type = QUOTE, value = ', position = 34), Token(type = RPAREN, value = ), position = 35), Token(type = SEMICOLON, value = ;, position = 37)]
2025-05-05 02:55:45,184 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 02:55:45,184 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 02:55:45,184 - compiler.parser - DEBUG - Found table name: users
2025-05-05 02:55:45,186 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 02:55:45,186 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 18)
2025-05-05 02:55:45,186 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 25)
2025-05-05 02:55:45,186 - compiler.parser - DEBUG - Found value: 1
2025-05-05 02:55:45,186 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 26)
2025-05-05 02:55:45,186 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 27)
2025-05-05 02:56:33,694 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = VALUES, position = 18), Token(type = LPAREN, value = (, position = 25), Token(type = NUMBER, value = 1, position = 26), Token(type = COMMA, value = ,, position = 27), Token(type = QUOTE, value = ', position = 29), Token(type = IDENTIFIER, value = John, position = 30), Token(type = QUOTE, value = ', position = 34), Token(type = RPAREN, value = ), position = 35), Token(type = SEMICOLON, value = ;, position = 36)]
2025-05-05 02:56:33,703 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 02:56:33,703 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 02:56:33,703 - compiler.parser - DEBUG - Found table name: users
2025-05-05 02:56:33,703 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 02:56:33,703 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 18)
2025-05-05 02:56:33,703 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 25)
2025-05-05 02:57:23,229 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = VALUES, position = 18), Token(type = LPAREN, value = (, position = 25), Token(type = NUMBER, value = 1, position = 26), Token(type = COMMA, value = ,, position = 27), Token(type = QUOTE, value = ', position = 29), Token(type = IDENTIFIER, value = John, position = 30), Token(type = QUOTE, value = ', position = 34), Token(type = RPAREN, value = ), position = 35), Token(type = SEMICOLON, value = ;, position = 36)]
2025-05-05 02:57:23,233 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 02:57:23,233 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 02:57:23,233 - compiler.parser - DEBUG - Found table name: users
2025-05-05 02:57:23,233 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 02:57:23,233 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 18)
2025-05-05 02:57:23,233 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 25)
2025-05-05 02:57:23,233 - compiler.parser - DEBUG - Found value: 1
2025-05-05 02:57:23,233 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 26)
2025-05-05 02:57:23,233 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 27)
2025-05-05 02:57:48,057 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = me, position = 7)]
2025-05-05 02:57:48,060 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-05 02:57:48,061 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 02:57:48,061 - compiler.parser - DEBUG - Found table name: me
2025-05-05 02:57:48,061 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = me, position = 7)
2025-05-05 02:57:48,061 - compiler.statements.update_parser - DEBUG - UPDATE table: me
2025-05-05 02:58:30,782 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = Customers, position = 7), Token(type = KEYWORD, value = SET, position = 17), Token(type = IDENTIFIER, value = ContactName, position = 21), Token(type = EQUALS, value = =, position = 33), Token(type = QUOTE, value = ', position = 35), Token(type = IDENTIFIER, value = Alfred, position = 36), Token(type = IDENTIFIER, value = Schmidt, position = 43), Token(type = QUOTE, value = ', position = 50), Token(type = COMMA, value = ,, position = 51), Token(type = IDENTIFIER, value = City, position = 53), Token(type = EQUALS, value = =, position = 57), Token(type = QUOTE, value = ', position = 59), Token(type = IDENTIFIER, value = Frankfurt, position = 60), Token(type = QUOTE, value = ', position = 69), Token(type = KEYWORD, value = WHERE, position = 71), Token(type = IDENTIFIER, value = CustomerID, position = 77), Token(type = EQUALS, value = =, position = 88), Token(type = NUMBER, value = 1, position = 90), Token(type = SEMICOLON, value = ;, position = 91)]
2025-05-05 02:58:30,784 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-05 02:58:30,784 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 02:58:30,784 - compiler.parser - DEBUG - Found table name: Customers
2025-05-05 02:58:30,784 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = Customers, position = 7)
2025-05-05 02:58:30,784 - compiler.statements.update_parser - DEBUG - UPDATE table: Customers
2025-05-05 02:58:30,784 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 17)
2025-05-05 02:58:30,784 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = ContactName, position = 21)
2025-05-05 02:58:30,784 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 33)
2025-05-05 02:58:30,784 - compiler.parser - DEBUG - Processed token: Token(type = QUOTE, value = ', position = 35)
2025-05-05 02:58:30,784 - compiler.statements.update_parser - DEBUG - SET clause: [('ContactName', "'")]
2025-05-05 02:58:30,784 - compiler.statements.update_parser - INFO - UPDATE parsed: table = Customers, SET = [('ContactName', "'")], WHERE = None
2025-05-05 03:19:57,847 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = KEYWORD, value = TABLE, position = 14)]
2025-05-05 03:19:57,850 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 03:19:57,850 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-05 03:19:57,850 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-05 03:19:57,850 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-05 03:19:57,850 - compiler.parser - ERROR - Expected at least one table in SELECT statement.
2025-05-05 03:20:12,260 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = dffdf, position = 14)]
2025-05-05 03:20:12,261 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 03:20:12,261 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-05 03:20:12,261 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-05 03:20:12,261 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-05 03:20:12,261 - compiler.parser - DEBUG - Found Table: dffdf
2025-05-05 03:20:12,261 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = dffdf, position = 14)
2025-05-05 03:20:12,261 - compiler.statements.select_parser - INFO - SELECT parsed: columns = ['*'], tables = ['dffdf']
2025-05-05 03:21:27,817 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = dffdf, position = 14)]
2025-05-05 03:21:27,820 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 03:21:27,821 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-05 03:21:27,821 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-05 03:21:27,821 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-05 03:21:27,821 - compiler.parser - DEBUG - Found Table: dffdf
2025-05-05 03:21:27,821 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = dffdf, position = 14)
2025-05-05 03:21:27,821 - compiler.statements.select_parser - INFO - SELECT parsed: columns = ['*'], tables = ['dffdf']
2025-05-05 03:24:35,328 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = dfdfd, position = 14)]
2025-05-05 03:24:35,330 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 03:24:35,330 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-05 03:24:35,330 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-05 03:24:35,330 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-05 03:24:35,330 - compiler.parser - DEBUG - Found Table: dfdfd
2025-05-05 03:24:35,330 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = dfdfd, position = 14)
2025-05-05 03:24:35,330 - compiler.statements.select_parser - INFO - SELECT parsed: columns = ['*'], tables = ['dfdfd']
2025-05-05 03:27:25,717 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = fndjdf, position = 14), Token(type = KEYWORD, value = WHERE, position = 21), Token(type = IDENTIFIER, value = id, position = 27), Token(type = EQUALS, value = =, position = 30), Token(type = NUMBER, value = 1, position = 31), Token(type = SEMICOLON, value = ;, position = 32)]
2025-05-05 03:27:25,720 - compiler.statements.select_parser - DEBUG - Parsing SELECT statement...
2025-05-05 03:27:25,720 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 03:27:25,720 - compiler.parser - DEBUG - Found '*' , selecting all columns....
2025-05-05 03:27:25,720 - compiler.parser - DEBUG - Processed token: Token(type = ASTERISK, value = *, position = 7)
2025-05-05 03:27:25,720 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-05 03:27:25,720 - compiler.parser - DEBUG - Found Table: fndjdf
2025-05-05 03:27:25,720 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = fndjdf, position = 14)
2025-05-05 03:27:25,720 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 21)
2025-05-05 03:27:25,720 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 27)
2025-05-05 03:27:25,720 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 30)
2025-05-05 03:27:25,720 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 31)
2025-05-05 03:28:23,823 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = id, position = 7), Token(type = COMMA, value = ,, position = 9), Token(type = IDENTIFIER, value = name, position = 11), Token(type = KEYWORD, value = FROM, position = 16), Token(type = IDENTIFIER, value = employees, position = 21), Token(type = KEYWORD, value = WHERE, position = 31), Token(type = IDENTIFIER, value = age, position = 37), Token(type = EQUALS, value = =, position = 41), Token(type = NUMBER, value = 30, position = 43), Token(type = SEMICOLON, value = ;, position = 45)]
2025-05-05 03:28:23,831 - compiler.statements.select_parser - DEBUG - Parsing SELECT statement...
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Found Column: id
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 7)
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 9)
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Found Column: name
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = name, position = 11)
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 16)
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Found Table: employees
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = employees, position = 21)
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 31)
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = age, position = 37)
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 41)
2025-05-05 03:28:23,831 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 30, position = 43)
2025-05-05 03:28:41,669 - compiler.tokenizer - ERROR - Invalid token at 33: "
2025-05-05 03:32:26,986 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = products, position = 12), Token(type = KEYWORD, value = VALUES, position = 21), Token(type = NUMBER, value = 101, position = 28), Token(type = COMMA, value = ,, position = 31), Token(type = STRING, value = Laptop, position = 33), Token(type = COMMA, value = ,, position = 41), Token(type = NUMBER, value = 899.99, position = 43), Token(type = SEMICOLON, value = ;, position = 49)]
2025-05-05 03:32:26,992 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 03:32:26,992 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 03:32:26,992 - compiler.parser - DEBUG - Found table name: products
2025-05-05 03:32:26,992 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 12)
2025-05-05 03:32:26,992 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 21)
2025-05-05 03:33:06,491 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = products, position = 12), Token(type = KEYWORD, value = VALUES, position = 21), Token(type = NUMBER, value = 101, position = 28), Token(type = COMMA, value = ,, position = 31), Token(type = STRING, value = Laptop, position = 33), Token(type = COMMA, value = ,, position = 41), Token(type = NUMBER, value = 899.99, position = 43), Token(type = SEMICOLON, value = ;, position = 49), Token(type = KEYWORD, value = INSERT, position = 50), Token(type = KEYWORD, value = INTO, position = 57), Token(type = IDENTIFIER, value = products, position = 62), Token(type = KEYWORD, value = VALUES, position = 71), Token(type = LPAREN, value = (, position = 78), Token(type = NUMBER, value = 101, position = 79), Token(type = COMMA, value = ,, position = 82), Token(type = STRING, value = Laptop, position = 84), Token(type = COMMA, value = ,, position = 92), Token(type = NUMBER, value = 899.99, position = 94), Token(type = RPAREN, value = ), position = 100), Token(type = SEMICOLON, value = ;, position = 101)]
2025-05-05 03:33:06,501 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 03:33:06,501 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 03:33:06,501 - compiler.parser - DEBUG - Found table name: products
2025-05-05 03:33:06,501 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 12)
2025-05-05 03:33:06,501 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 21)
2025-05-05 03:33:10,165 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = products, position = 12), Token(type = KEYWORD, value = VALUES, position = 21), Token(type = LPAREN, value = (, position = 28), Token(type = NUMBER, value = 101, position = 29), Token(type = COMMA, value = ,, position = 32), Token(type = STRING, value = Laptop, position = 34), Token(type = COMMA, value = ,, position = 42), Token(type = NUMBER, value = 899.99, position = 44), Token(type = RPAREN, value = ), position = 50), Token(type = SEMICOLON, value = ;, position = 51)]
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Found table name: products
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 12)
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 21)
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 28)
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Found value: 101
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 101, position = 29)
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 32)
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Found value: Laptop
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Processed token: Token(type = STRING, value = Laptop, position = 34)
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 42)
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Found value: 899.99
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 899.99, position = 44)
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 50)
2025-05-05 03:33:10,170 - compiler.parser - DEBUG - Processed token: Token(type = SEMICOLON, value = ;, position = 51)
2025-05-05 03:33:10,175 - compiler.code_generator - ERROR - Unsupported statement type: insert
2025-05-05 03:33:26,347 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = products, position = 12), Token(type = KEYWORD, value = VALUES, position = 21), Token(type = LPAREN, value = (, position = 28), Token(type = NUMBER, value = 101, position = 29), Token(type = COMMA, value = ,, position = 32), Token(type = STRING, value = Laptop, position = 34), Token(type = COMMA, value = ,, position = 42), Token(type = NUMBER, value = 899.99, position = 44), Token(type = RPAREN, value = ), position = 50), Token(type = SEMICOLON, value = ;, position = 51)]
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Found table name: products
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 12)
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 21)
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 28)
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Found value: 101
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 101, position = 29)
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 32)
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Found value: Laptop
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Processed token: Token(type = STRING, value = Laptop, position = 34)
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 42)
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Found value: 899.99
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 899.99, position = 44)
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 50)
2025-05-05 03:33:26,352 - compiler.parser - DEBUG - Processed token: Token(type = SEMICOLON, value = ;, position = 51)
2025-05-05 03:33:26,355 - compiler.code_generator - ERROR - Unsupported statement type: insert
2025-05-05 03:39:00,445 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = products, position = 12), Token(type = KEYWORD, value = VALUES, position = 21), Token(type = LPAREN, value = (, position = 28), Token(type = NUMBER, value = 101, position = 29), Token(type = COMMA, value = ,, position = 32), Token(type = STRING, value = Laptop, position = 34), Token(type = COMMA, value = ,, position = 42), Token(type = NUMBER, value = 899.99, position = 44), Token(type = RPAREN, value = ), position = 50), Token(type = SEMICOLON, value = ;, position = 51)]
2025-05-05 03:39:00,451 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Found table name: products
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 12)
2025-05-05 03:39:00,452 - compiler.statements.insert_parser - DEBUG - Parsed table name: products
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 21)
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 28)
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Found value: 101
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 101, position = 29)
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 32)
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Found value: Laptop
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Processed token: Token(type = STRING, value = Laptop, position = 34)
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 42)
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Found value: 899.99
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 899.99, position = 44)
2025-05-05 03:39:00,452 - compiler.statements.insert_parser - DEBUG - Parsed values: ['101', 'Laptop', '899.99']
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 50)
2025-05-05 03:39:00,452 - compiler.parser - DEBUG - Processed token: Token(type = SEMICOLON, value = ;, position = 51)
2025-05-05 03:39:00,452 - compiler.code_generator - ERROR - Unsupported statement type: insert
2025-05-05 03:40:48,680 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = products, position = 12), Token(type = KEYWORD, value = VALUES, position = 21), Token(type = LPAREN, value = (, position = 28), Token(type = NUMBER, value = 101, position = 29), Token(type = COMMA, value = ,, position = 32), Token(type = STRING, value = Laptop, position = 34), Token(type = COMMA, value = ,, position = 42), Token(type = NUMBER, value = 899.99, position = 44), Token(type = RPAREN, value = ), position = 50), Token(type = SEMICOLON, value = ;, position = 51)]
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Found table name: products
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 12)
2025-05-05 03:40:48,688 - compiler.statements.insert_parser - DEBUG - Parsed table name: products
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 21)
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 28)
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Found value: 101
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 101, position = 29)
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 32)
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Found value: Laptop
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Processed token: Token(type = STRING, value = Laptop, position = 34)
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 42)
2025-05-05 03:40:48,688 - compiler.parser - DEBUG - Found value: 899.99
2025-05-05 03:40:48,689 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 899.99, position = 44)
2025-05-05 03:40:48,689 - compiler.statements.insert_parser - DEBUG - Parsed values: ['101', 'Laptop', '899.99']
2025-05-05 03:40:48,689 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 50)
2025-05-05 03:40:48,689 - compiler.parser - DEBUG - Processed token: Token(type = SEMICOLON, value = ;, position = 51)
2025-05-05 03:40:48,689 - compiler.parser - INFO - Handling insert for table 'products' with values ['101', 'Laptop', '899.99']
2025-05-05 03:40:48,691 - compiler.code_generator - ERROR - Unsupported statement type: insert
2025-05-05 03:41:57,669 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = products, position = 12), Token(type = KEYWORD, value = VALUES, position = 21), Token(type = LPAREN, value = (, position = 28), Token(type = NUMBER, value = 101, position = 29), Token(type = COMMA, value = ,, position = 32), Token(type = STRING, value = Laptop, position = 34), Token(type = COMMA, value = ,, position = 42), Token(type = NUMBER, value = 899.99, position = 44), Token(type = RPAREN, value = ), position = 50), Token(type = SEMICOLON, value = ;, position = 51)]
2025-05-05 03:43:45,360 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = products, position = 12), Token(type = KEYWORD, value = VALUES, position = 21), Token(type = LPAREN, value = (, position = 28), Token(type = NUMBER, value = 101, position = 29), Token(type = COMMA, value = ,, position = 32), Token(type = STRING, value = Laptop, position = 34), Token(type = COMMA, value = ,, position = 42), Token(type = NUMBER, value = 899.99, position = 44), Token(type = RPAREN, value = ), position = 50), Token(type = SEMICOLON, value = ;, position = 51)]
2025-05-05 03:44:50,490 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = products, position = 12), Token(type = KEYWORD, value = VALUES, position = 21), Token(type = LPAREN, value = (, position = 28), Token(type = NUMBER, value = 101, position = 29), Token(type = COMMA, value = ,, position = 32), Token(type = STRING, value = Laptop, position = 34), Token(type = COMMA, value = ,, position = 42), Token(type = NUMBER, value = 899.99, position = 44), Token(type = RPAREN, value = ), position = 50), Token(type = SEMICOLON, value = ;, position = 51)]
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Found table name: products
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 12)
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 21)
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 28)
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Found value: 101
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 101, position = 29)
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 32)
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Found value: Laptop
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Processed token: Token(type = STRING, value = Laptop, position = 34)
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 42)
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Found value: 899.99
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 899.99, position = 44)
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 50)
2025-05-05 03:44:50,492 - compiler.parser - DEBUG - Processed token: Token(type = SEMICOLON, value = ;, position = 51)
2025-05-05 03:44:50,492 - compiler.parser - INFO - Handling insert for table 'products' with values ['101', 'Laptop', '899.99']
2025-05-05 03:44:50,498 - compiler.code_generator - ERROR - Unsupported statement type: insert
2025-05-05 03:47:07,632 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = products, position = 12), Token(type = KEYWORD, value = VALUES, position = 21), Token(type = LPAREN, value = (, position = 28), Token(type = NUMBER, value = 101, position = 29), Token(type = COMMA, value = ,, position = 32), Token(type = STRING, value = Laptop, position = 34), Token(type = COMMA, value = ,, position = 42), Token(type = NUMBER, value = 899.99, position = 44), Token(type = RPAREN, value = ), position = 50), Token(type = SEMICOLON, value = ;, position = 51)]
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Found table name: products
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 12)
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 21)
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 28)
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Found value: 101
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 101, position = 29)
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 32)
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Found value: Laptop
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Processed token: Token(type = STRING, value = Laptop, position = 34)
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 42)
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Found value: 899.99
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 899.99, position = 44)
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 50)
2025-05-05 03:47:07,634 - compiler.parser - DEBUG - Processed token: Token(type = SEMICOLON, value = ;, position = 51)
2025-05-05 03:47:07,634 - compiler.parser - INFO - Handling insert for table 'products' with values ['101', 'Laptop', '899.99']
2025-05-05 03:47:07,641 - compiler.code_generator - ERROR - Unsupported statement type: insert
2025-05-05 03:49:12,008 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = products, position = 12), Token(type = KEYWORD, value = VALUES, position = 21), Token(type = LPAREN, value = (, position = 28), Token(type = NUMBER, value = 101, position = 29), Token(type = COMMA, value = ,, position = 32), Token(type = STRING, value = Laptop, position = 34), Token(type = COMMA, value = ,, position = 42), Token(type = NUMBER, value = 899.99, position = 44), Token(type = RPAREN, value = ), position = 50), Token(type = SEMICOLON, value = ;, position = 51)]
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Found table name: products
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 12)
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 21)
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 28)
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Found value: 101
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 101, position = 29)
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 32)
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Found value: Laptop
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Processed token: Token(type = STRING, value = Laptop, position = 34)
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 42)
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Found value: 899.99
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 899.99, position = 44)
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 50)
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Processed token: Token(type = SEMICOLON, value = ;, position = 51)
2025-05-05 03:49:12,011 - compiler.parser - INFO - Handling insert for table 'products' with values ['101', 'Laptop', '899.99']
2025-05-05 03:49:12,011 - compiler.parser - DEBUG - Parsed Insert: {'type': 'insert', 'table_name': 'products', 'values': ['101', 'Laptop', '899.99']}
2025-05-05 03:49:12,011 - compiler.code_generator - ERROR - Unsupported statement type: insert
2025-05-05 03:50:46,030 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = naman, position = 13)]
2025-05-05 03:50:46,032 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 03:50:46,032 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 03:50:46,032 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 03:50:46,032 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 03:50:46,032 - compiler.statements.create_parser - DEBUG - Column Found: naman
2025-05-05 03:50:46,032 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = naman, position = 13)
2025-05-05 03:51:20,343 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = users, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 20), Token(type = IDENTIFIER, value = INT, position = 23), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = name, position = 28), Token(type = IDENTIFIER, value = TEXT, position = 33), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = age, position = 39), Token(type = IDENTIFIER, value = INT, position = 43), Token(type = RPAREN, value = ), position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-05 03:51:20,346 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 03:51:20,346 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 03:51:20,346 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 03:51:20,346 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 03:51:20,346 - compiler.statements.create_parser - DEBUG - Column Found: users
2025-05-05 03:51:20,346 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 13)
2025-05-05 03:51:20,346 - compiler.statements.create_parser - ERROR - Expected Column Type...

2025-05-05 03:51:44,259 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = users, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 20), Token(type = IDENTIFIER, value = INT, position = 23), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = name, position = 28), Token(type = IDENTIFIER, value = TEXT, position = 33), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = age, position = 39), Token(type = IDENTIFIER, value = INT, position = 43), Token(type = RPAREN, value = ), position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-05 03:51:44,268 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 03:51:44,268 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 03:51:44,269 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 03:51:44,269 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 03:51:44,269 - compiler.statements.create_parser - DEBUG - Column Found: users
2025-05-05 03:51:44,269 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 13)
2025-05-05 03:51:44,269 - compiler.statements.create_parser - ERROR - Expected Column Type...

2025-05-05 03:53:11,986 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = users, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 20), Token(type = IDENTIFIER, value = INT, position = 23), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = name, position = 28), Token(type = IDENTIFIER, value = TEXT, position = 33), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = age, position = 39), Token(type = IDENTIFIER, value = INT, position = 43), Token(type = RPAREN, value = ), position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-05 03:53:11,997 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 03:53:11,998 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 03:53:11,998 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 03:53:11,998 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 03:53:11,998 - compiler.statements.create_parser - DEBUG - Column Found: users
2025-05-05 03:53:11,998 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 13)
2025-05-05 03:53:11,998 - compiler.statements.create_parser - ERROR - Expected Column Type...

2025-05-05 03:54:24,091 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = users, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 20), Token(type = IDENTIFIER, value = INT, position = 23), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = name, position = 28), Token(type = IDENTIFIER, value = TEXT, position = 33), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = age, position = 39), Token(type = IDENTIFIER, value = INT, position = 43), Token(type = RPAREN, value = ), position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Found table name: users
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 13)
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 19)
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 20)
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = INT, position = 23)
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 26)
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = name, position = 28)
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = TEXT, position = 33)
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 37)
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = age, position = 39)
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = INT, position = 43)
2025-05-05 03:54:24,096 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 46)
2025-05-05 03:54:24,097 - compiler.parser - DEBUG - Processed token: Token(type = SEMICOLON, value = ;, position = 47)
2025-05-05 03:54:24,101 - compiler.code_generator - ERROR - Unsupported statement type: create
2025-05-05 03:55:02,904 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = users, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 20), Token(type = IDENTIFIER, value = INT, position = 23), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = name, position = 28), Token(type = IDENTIFIER, value = TEXT, position = 33), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = age, position = 39), Token(type = IDENTIFIER, value = INT, position = 43), Token(type = RPAREN, value = ), position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-05 03:55:06,227 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = users, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 20), Token(type = IDENTIFIER, value = INT, position = 23), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = name, position = 28), Token(type = IDENTIFIER, value = TEXT, position = 33), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = age, position = 39), Token(type = IDENTIFIER, value = INT, position = 43), Token(type = RPAREN, value = ), position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-05 03:55:33,359 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = users, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 20), Token(type = IDENTIFIER, value = INT, position = 23), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = name, position = 28), Token(type = IDENTIFIER, value = TEXT, position = 33), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = age, position = 39), Token(type = IDENTIFIER, value = INT, position = 43), Token(type = RPAREN, value = ), position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-05 03:55:33,365 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 03:55:33,365 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 03:55:33,365 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 03:55:33,365 - compiler.statements.create_parser - DEBUG - Table name: users
2025-05-05 03:55:33,365 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 13)
2025-05-05 03:56:35,274 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = users, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 20), Token(type = IDENTIFIER, value = INT, position = 23), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = name, position = 28), Token(type = IDENTIFIER, value = TEXT, position = 33), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = age, position = 39), Token(type = IDENTIFIER, value = INT, position = 43), Token(type = RPAREN, value = ), position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-05 03:56:35,279 - compiler.parser - INFO - Parsing Create Table.... 

2025-05-05 03:56:35,279 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 03:56:35,280 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 03:56:35,280 - compiler.parser - DEBUG - Parsing Columns.....

2025-05-05 03:56:35,280 - compiler.parser - DEBUG - Column Found: users
2025-05-05 03:56:35,280 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 13)
2025-05-05 03:56:35,280 - compiler.parser - ERROR - Expected Column Type...

2025-05-05 03:57:37,666 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = users, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 20), Token(type = IDENTIFIER, value = INT, position = 23), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = name, position = 28), Token(type = IDENTIFIER, value = TEXT, position = 33), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = age, position = 39), Token(type = IDENTIFIER, value = INT, position = 43), Token(type = RPAREN, value = ), position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-05 03:57:37,671 - compiler.parser - INFO - Parsing Create Table.... 

2025-05-05 03:57:37,671 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 03:57:37,671 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 03:57:37,671 - compiler.parser - DEBUG - Parsing Columns.....

2025-05-05 03:57:37,671 - compiler.parser - DEBUG - Column Found: users
2025-05-05 03:57:37,671 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 13)
2025-05-05 03:57:37,672 - compiler.parser - ERROR - Expected column type (e.g., INT, TEXT), but got LPAREN - (
2025-05-05 03:59:22,664 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = users, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 20), Token(type = IDENTIFIER, value = INT, position = 23), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = name, position = 28), Token(type = IDENTIFIER, value = TEXT, position = 33), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = age, position = 39), Token(type = IDENTIFIER, value = INT, position = 43), Token(type = RPAREN, value = ), position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-05 03:59:22,667 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 03:59:22,667 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 03:59:22,667 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 03:59:22,667 - compiler.statements.create_parser - DEBUG - Table Name Found: users
2025-05-05 03:59:22,667 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 13)
2025-05-05 03:59:22,667 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 19)
2025-05-05 03:59:22,667 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 03:59:22,667 - compiler.statements.create_parser - DEBUG - Column Found: id
2025-05-05 03:59:22,667 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 20)
2025-05-05 03:59:22,667 - compiler.statements.create_parser - ERROR - Expected column type (e.g., INT, TEXT), but got IDENTIFIER - INT
2025-05-05 04:02:11,305 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = users, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 20), Token(type = KEYWORD, value = INT, position = 23), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = name, position = 28), Token(type = KEYWORD, value = TEXT, position = 33), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = age, position = 39), Token(type = KEYWORD, value = INT, position = 43), Token(type = RPAREN, value = ), position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-05 04:02:11,306 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 04:02:11,306 - compiler.statements.create_parser - DEBUG - Table Name Found: users
2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 13)
2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 19)
2025-05-05 04:02:11,306 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 04:02:11,306 - compiler.statements.create_parser - DEBUG - Column Found: id
2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 20)
2025-05-05 04:02:11,306 - compiler.statements.create_parser - DEBUG - Column Type: INT
2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INT, position = 23)
2025-05-05 04:02:11,306 - compiler.statements.create_parser - DEBUG - Found ',' moving to next column....
2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 26)
2025-05-05 04:02:11,306 - compiler.statements.create_parser - DEBUG - Column Found: name
2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = name, position = 28)
2025-05-05 04:02:11,306 - compiler.statements.create_parser - DEBUG - Column Type: TEXT
2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TEXT, position = 33)
2025-05-05 04:02:11,306 - compiler.statements.create_parser - DEBUG - Found ',' moving to next column....
2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 37)
2025-05-05 04:02:11,306 - compiler.statements.create_parser - DEBUG - Column Found: age
2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = age, position = 39)
2025-05-05 04:02:11,306 - compiler.statements.create_parser - DEBUG - Column Type: INT
2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INT, position = 43)
2025-05-05 04:02:11,306 - compiler.statements.create_parser - DEBUG - Found ')' moving to next column....
2025-05-05 04:02:11,306 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 46)
2025-05-05 04:02:11,306 - compiler.statements.create_parser - INFO - CREATE TABLE parsed successfully with columns: [('id', 'INT'), ('name', 'TEXT'), ('age', 'INT')]
2025-05-05 04:02:11,315 - compiler.code_generator - DEBUG - Accessing columns and Table Name....
2025-05-05 04:02:11,315 - compiler.code_generator - INFO - Accessing Columns and Table Name finished....
2025-05-05 04:02:38,786 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = LPAREN, value = (, position = 18), Token(type = IDENTIFIER, value = id, position = 19), Token(type = COMMA, value = ,, position = 21), Token(type = IDENTIFIER, value = name, position = 23), Token(type = COMMA, value = ,, position = 27), Token(type = IDENTIFIER, value = age, position = 29), Token(type = RPAREN, value = ), position = 32), Token(type = KEYWORD, value = VALUES, position = 34), Token(type = LPAREN, value = (, position = 41), Token(type = NUMBER, value = 1, position = 42), Token(type = COMMA, value = ,, position = 43), Token(type = QUOTE, value = ', position = 45), Token(type = IDENTIFIER, value = John, position = 46), Token(type = IDENTIFIER, value = Doe, position = 51), Token(type = QUOTE, value = ', position = 54), Token(type = COMMA, value = ,, position = 55), Token(type = NUMBER, value = 30, position = 57), Token(type = RPAREN, value = ), position = 59), Token(type = SEMICOLON, value = ;, position = 60)]
2025-05-05 04:02:38,790 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 04:02:38,790 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 04:02:38,790 - compiler.parser - DEBUG - Found table name: users
2025-05-05 04:02:38,790 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:03:04,095 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = WHERE, position = 18), Token(type = IDENTIFIER, value = id, position = 24), Token(type = EQUALS, value = =, position = 27), Token(type = NUMBER, value = 1, position = 29), Token(type = SEMICOLON, value = ;, position = 30)]
2025-05-05 04:03:04,095 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 04:03:04,095 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 04:03:04,095 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 7)
2025-05-05 04:03:04,095 - compiler.parser - DEBUG - Found table name: users
2025-05-05 04:03:04,095 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:03:04,095 - compiler.statements.delete_parser - DEBUG - DELETE FROM: users
2025-05-05 04:03:04,095 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 18)
2025-05-05 04:04:10,774 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = WHERE, position = 18), Token(type = IDENTIFIER, value = id, position = 24), Token(type = EQUALS, value = =, position = 27), Token(type = NUMBER, value = 1, position = 29), Token(type = SEMICOLON, value = ;, position = 30)]
2025-05-05 04:04:10,776 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 04:04:10,776 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 04:04:10,776 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 7)
2025-05-05 04:04:10,776 - compiler.parser - DEBUG - Found table name: users
2025-05-05 04:04:10,776 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:04:10,776 - compiler.statements.delete_parser - DEBUG - DELETE FROM: users
2025-05-05 04:04:10,776 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 18)
2025-05-05 04:04:10,776 - compiler.parser - DEBUG - Parsing WHERE condition....
2025-05-05 04:04:10,776 - compiler.parser - DEBUG - Column Found: id
2025-05-05 04:04:10,776 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 24)
2025-05-05 04:04:10,776 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 27)
2025-05-05 04:04:10,776 - compiler.parser - DEBUG - Value Found: 1
2025-05-05 04:04:10,776 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 29)
2025-05-05 04:04:10,776 - compiler.statements.delete_parser - DEBUG - WHERE condition: {'column': 'id', 'value': '1'}
2025-05-05 04:04:10,776 - compiler.statements.delete_parser - INFO - DELETE parsed: table = users, WHERE condition = {'column': 'id', 'value': '1'}
2025-05-05 04:06:38,289 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = WHERE, position = 18), Token(type = IDENTIFIER, value = id, position = 24), Token(type = EQUALS, value = =, position = 27), Token(type = NUMBER, value = 1, position = 29), Token(type = SEMICOLON, value = ;, position = 30)]
2025-05-05 04:06:38,291 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 04:06:38,291 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 04:06:38,291 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 7)
2025-05-05 04:06:38,291 - compiler.parser - DEBUG - Found table name: users
2025-05-05 04:06:38,294 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:06:38,294 - compiler.statements.delete_parser - DEBUG - DELETE FROM: users
2025-05-05 04:06:38,294 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 18)
2025-05-05 04:06:38,294 - compiler.parser - DEBUG - Parsing WHERE condition....
2025-05-05 04:06:38,294 - compiler.parser - DEBUG - Column Found: id
2025-05-05 04:06:38,294 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 24)
2025-05-05 04:06:38,294 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 27)
2025-05-05 04:06:38,294 - compiler.parser - DEBUG - Value Found: 1
2025-05-05 04:06:38,294 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 29)
2025-05-05 04:06:38,294 - compiler.statements.delete_parser - DEBUG - WHERE condition: {'column': 'id', 'value': '1'}
2025-05-05 04:06:38,294 - compiler.statements.delete_parser - INFO - DELETE parsed: table = users, WHERE condition = {'column': 'id', 'value': '1'}
2025-05-05 04:07:14,225 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = WHERE, position = 18), Token(type = IDENTIFIER, value = id, position = 24), Token(type = EQUALS, value = =, position = 27), Token(type = NUMBER, value = 1, position = 29), Token(type = SEMICOLON, value = ;, position = 30)]
2025-05-05 04:07:14,228 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 04:07:14,228 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 04:07:14,228 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 7)
2025-05-05 04:07:14,228 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 04:07:14,229 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 04:07:14,229 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:07:14,229 - compiler.statements.delete_parser - DEBUG - DELETE FROM: users
2025-05-05 04:07:14,229 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 18)
2025-05-05 04:07:14,229 - compiler.parser - DEBUG - Parsing WHERE condition....
2025-05-05 04:07:14,229 - compiler.parser - DEBUG - Column Found: id
2025-05-05 04:07:14,229 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 24)
2025-05-05 04:07:14,229 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 27)
2025-05-05 04:07:14,229 - compiler.parser - DEBUG - Value Found: 1
2025-05-05 04:07:14,229 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 29)
2025-05-05 04:07:14,229 - compiler.statements.delete_parser - DEBUG - WHERE condition: {'column': 'id', 'value': '1'}
2025-05-05 04:07:14,229 - compiler.statements.delete_parser - INFO - DELETE parsed: table = users, WHERE condition = {'column': 'id', 'value': '1'}
2025-05-05 04:10:47,846 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = WHERE, position = 18), Token(type = IDENTIFIER, value = id, position = 24), Token(type = EQUALS, value = =, position = 27), Token(type = NUMBER, value = 1, position = 29), Token(type = SEMICOLON, value = ;, position = 30)]
2025-05-05 04:10:47,849 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 04:10:47,849 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 04:10:47,849 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 7)
2025-05-05 04:10:47,849 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 04:10:47,849 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 04:10:47,849 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:10:47,849 - compiler.statements.delete_parser - DEBUG - DELETE FROM: users
2025-05-05 04:10:47,849 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 18)
2025-05-05 04:10:47,849 - compiler.parser - DEBUG - Parsing WHERE condition....
2025-05-05 04:10:47,849 - compiler.parser - DEBUG - Column Found: id
2025-05-05 04:10:47,849 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 24)
2025-05-05 04:10:47,849 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 27)
2025-05-05 04:10:47,849 - compiler.parser - DEBUG - Value Found: 1
2025-05-05 04:10:47,849 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 29)
2025-05-05 04:10:47,849 - compiler.statements.delete_parser - DEBUG - WHERE condition: {'column': 'id', 'value': '1'}
2025-05-05 04:10:47,849 - compiler.statements.delete_parser - INFO - DELETE parsed: table = users, WHERE condition = {'column': 'id', 'value': '1'}
2025-05-05 04:12:29,639 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = WHERE, position = 18), Token(type = IDENTIFIER, value = id, position = 24), Token(type = EQUALS, value = =, position = 27), Token(type = NUMBER, value = 1, position = 29), Token(type = SEMICOLON, value = ;, position = 30)]
2025-05-05 04:12:29,643 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 04:12:29,644 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 04:12:29,644 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 7)
2025-05-05 04:12:29,644 - compiler.statements.delete_parser - DEBUG - Token before table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:12:29,644 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 04:12:29,644 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 04:12:29,644 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:12:29,644 - compiler.statements.delete_parser - DEBUG - DELETE FROM: users
2025-05-05 04:12:29,644 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 18)
2025-05-05 04:12:29,644 - compiler.parser - DEBUG - Parsing WHERE condition....
2025-05-05 04:12:29,644 - compiler.parser - DEBUG - Column Found: id
2025-05-05 04:12:29,644 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 24)
2025-05-05 04:12:29,644 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 27)
2025-05-05 04:12:29,644 - compiler.parser - DEBUG - Value Found: 1
2025-05-05 04:12:29,644 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 29)
2025-05-05 04:12:29,644 - compiler.statements.delete_parser - DEBUG - WHERE condition: {'column': 'id', 'value': '1'}
2025-05-05 04:12:29,644 - compiler.statements.delete_parser - INFO - DELETE parsed: table = users, WHERE condition = {'column': 'id', 'value': '1'}
2025-05-05 04:15:56,814 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = WHERE, position = 18), Token(type = IDENTIFIER, value = id, position = 24), Token(type = EQUALS, value = =, position = 27), Token(type = NUMBER, value = 1, position = 29), Token(type = SEMICOLON, value = ;, position = 30)]
2025-05-05 04:15:56,817 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 7)
2025-05-05 04:15:56,817 - compiler.statements.delete_parser - DEBUG - Token before table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:15:56,817 - compiler.statements.delete_parser - DEBUG - DELETE FROM: users
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 18)
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Parsing WHERE condition....
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Column Found: id
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 24)
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 27)
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Value Found: 1
2025-05-05 04:15:56,817 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 29)
2025-05-05 04:15:56,817 - compiler.statements.delete_parser - DEBUG - WHERE condition: {'column': 'id', 'value': '1'}
2025-05-05 04:15:56,817 - compiler.statements.delete_parser - INFO - DELETE parsed: table = users, WHERE condition = {'column': 'id', 'value': '1'}
2025-05-05 04:19:08,829 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = LPAREN, value = (, position = 18), Token(type = IDENTIFIER, value = id, position = 19), Token(type = COMMA, value = ,, position = 21), Token(type = IDENTIFIER, value = name, position = 23), Token(type = COMMA, value = ,, position = 27), Token(type = IDENTIFIER, value = age, position = 29), Token(type = RPAREN, value = ), position = 32), Token(type = KEYWORD, value = VALUES, position = 34), Token(type = LPAREN, value = (, position = 41), Token(type = NUMBER, value = 1, position = 42), Token(type = COMMA, value = ,, position = 43), Token(type = QUOTE, value = ', position = 45), Token(type = IDENTIFIER, value = John, position = 46), Token(type = IDENTIFIER, value = Doe, position = 51), Token(type = QUOTE, value = ', position = 54), Token(type = COMMA, value = ,, position = 55), Token(type = NUMBER, value = 30, position = 57), Token(type = RPAREN, value = ), position = 59), Token(type = SEMICOLON, value = ;, position = 60)]
2025-05-05 04:19:08,841 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 04:19:08,841 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 04:19:08,841 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 04:19:08,841 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:19:08,841 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 04:19:08,841 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:19:15,243 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = WHERE, position = 18), Token(type = IDENTIFIER, value = id, position = 24), Token(type = EQUALS, value = =, position = 27), Token(type = NUMBER, value = 1, position = 29), Token(type = SEMICOLON, value = ;, position = 30)]
2025-05-05 04:19:15,245 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 04:19:15,245 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 04:19:15,245 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 7)
2025-05-05 04:19:15,245 - compiler.statements.delete_parser - DEBUG - Token before table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:19:15,247 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 04:19:15,247 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:19:15,247 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 04:19:15,247 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:19:15,247 - compiler.statements.delete_parser - DEBUG - DELETE FROM: users
2025-05-05 04:19:15,247 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 18)
2025-05-05 04:19:15,247 - compiler.parser - DEBUG - Parsing WHERE condition....
2025-05-05 04:19:15,247 - compiler.parser - DEBUG - Column Found: id
2025-05-05 04:19:15,247 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 24)
2025-05-05 04:19:15,247 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 27)
2025-05-05 04:19:15,247 - compiler.parser - DEBUG - Value Found: 1
2025-05-05 04:19:15,247 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 29)
2025-05-05 04:19:15,247 - compiler.statements.delete_parser - DEBUG - WHERE condition: {'column': 'id', 'value': '1'}
2025-05-05 04:19:15,247 - compiler.statements.delete_parser - INFO - DELETE parsed: table = users, WHERE condition = {'column': 'id', 'value': '1'}
2025-05-05 04:19:20,083 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = users, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 20), Token(type = KEYWORD, value = INT, position = 23), Token(type = COMMA, value = ,, position = 26), Token(type = IDENTIFIER, value = name, position = 28), Token(type = KEYWORD, value = TEXT, position = 33), Token(type = COMMA, value = ,, position = 37), Token(type = IDENTIFIER, value = age, position = 39), Token(type = KEYWORD, value = INT, position = 43), Token(type = RPAREN, value = ), position = 46), Token(type = SEMICOLON, value = ;, position = 47)]
2025-05-05 04:19:20,092 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 04:19:20,092 - compiler.statements.create_parser - DEBUG - Table Name Found: users
2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 13)
2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 19)
2025-05-05 04:19:20,092 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 04:19:20,092 - compiler.statements.create_parser - DEBUG - Column Found: id
2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 20)
2025-05-05 04:19:20,092 - compiler.statements.create_parser - DEBUG - Column Type: INT
2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INT, position = 23)
2025-05-05 04:19:20,092 - compiler.statements.create_parser - DEBUG - Found ',' moving to next column....
2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 26)
2025-05-05 04:19:20,092 - compiler.statements.create_parser - DEBUG - Column Found: name
2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = name, position = 28)
2025-05-05 04:19:20,092 - compiler.statements.create_parser - DEBUG - Column Type: TEXT
2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TEXT, position = 33)
2025-05-05 04:19:20,092 - compiler.statements.create_parser - DEBUG - Found ',' moving to next column....
2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 37)
2025-05-05 04:19:20,092 - compiler.statements.create_parser - DEBUG - Column Found: age
2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = age, position = 39)
2025-05-05 04:19:20,092 - compiler.statements.create_parser - DEBUG - Column Type: INT
2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INT, position = 43)
2025-05-05 04:19:20,092 - compiler.statements.create_parser - DEBUG - Found ')' moving to next column....
2025-05-05 04:19:20,092 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 46)
2025-05-05 04:19:20,092 - compiler.statements.create_parser - INFO - CREATE TABLE parsed successfully with columns: [('id', 'INT'), ('name', 'TEXT'), ('age', 'INT')]
2025-05-05 04:19:20,094 - compiler.code_generator - DEBUG - Accessing columns and Table Name....
2025-05-05 04:19:20,095 - compiler.code_generator - INFO - Accessing Columns and Table Name finished....
2025-05-05 04:19:34,000 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DROP, position = 0), Token(type = IDENTIFIER, value = pinchu, position = 5)]
2025-05-05 04:19:34,001 - compiler.statements.drop_parser - INFO - Parsing DROP statement....
2025-05-05 04:19:34,001 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DROP, position = 0)
2025-05-05 04:19:34,001 - compiler.statements.drop_parser - ERROR - Expected 'TABLE' after DROP
2025-05-05 04:19:43,484 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DROP, position = 0), Token(type = IDENTIFIER, value = pinchu, position = 5), Token(type = SEMICOLON, value = ;, position = 11)]
2025-05-05 04:19:43,486 - compiler.statements.drop_parser - INFO - Parsing DROP statement....
2025-05-05 04:19:43,486 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DROP, position = 0)
2025-05-05 04:19:43,487 - compiler.statements.drop_parser - ERROR - Expected 'TABLE' after DROP
2025-05-05 04:20:53,803 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DROP, position = 0), Token(type = IDENTIFIER, value = pinchu, position = 5), Token(type = SEMICOLON, value = ;, position = 11)]
2025-05-05 04:20:53,805 - compiler.statements.drop_parser - INFO - Parsing DROP statement....
2025-05-05 04:20:53,805 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DROP, position = 0)
2025-05-05 04:20:53,805 - compiler.statements.drop_parser - DEBUG - Dropped Entity: pinchu
2025-05-05 04:20:53,805 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = pinchu, position = 5)
2025-05-05 04:20:53,806 - compiler.statements.drop_parser - INFO - DROP parsed: entity = pinchu
2025-05-05 04:24:45,509 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DROP, position = 0), Token(type = IDENTIFIER, value = pinchu, position = 5), Token(type = SEMICOLON, value = ;, position = 11)]
2025-05-05 04:24:45,511 - compiler.statements.drop_parser - INFO - Parsing DROP statement....
2025-05-05 04:24:45,511 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DROP, position = 0)
2025-05-05 04:24:45,511 - compiler.statements.drop_parser - DEBUG - Dropped Entity: pinchu
2025-05-05 04:24:45,511 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = pinchu, position = 5)
2025-05-05 04:24:45,511 - compiler.statements.drop_parser - INFO - DROP parsed: entity = pinchu
2025-05-05 04:25:05,795 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = KEYWORD, value = WHERE, position = 18), Token(type = IDENTIFIER, value = id, position = 24), Token(type = EQUALS, value = =, position = 27), Token(type = NUMBER, value = 1, position = 29), Token(type = SEMICOLON, value = ;, position = 30)]
2025-05-05 04:25:05,799 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 04:25:05,799 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 04:25:05,799 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 7)
2025-05-05 04:25:05,799 - compiler.statements.delete_parser - DEBUG - Token before table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:25:05,799 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 04:25:05,799 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:25:05,799 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 04:25:05,799 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:25:05,799 - compiler.statements.delete_parser - DEBUG - DELETE FROM: users
2025-05-05 04:25:05,800 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 18)
2025-05-05 04:25:05,800 - compiler.parser - DEBUG - Parsing WHERE condition....
2025-05-05 04:25:05,800 - compiler.parser - DEBUG - Column Found: id
2025-05-05 04:25:05,800 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 24)
2025-05-05 04:25:05,800 - compiler.parser - DEBUG - Processed token: Token(type = EQUALS, value = =, position = 27)
2025-05-05 04:25:05,800 - compiler.parser - DEBUG - Value Found: 1
2025-05-05 04:25:05,800 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 29)
2025-05-05 04:25:05,800 - compiler.statements.delete_parser - DEBUG - WHERE condition: {'column': 'id', 'value': '1'}
2025-05-05 04:25:05,800 - compiler.statements.delete_parser - INFO - DELETE parsed: table = users, WHERE condition = {'column': 'id', 'value': '1'}
2025-05-05 04:25:18,931 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = LPAREN, value = (, position = 18), Token(type = IDENTIFIER, value = id, position = 19), Token(type = COMMA, value = ,, position = 21), Token(type = IDENTIFIER, value = name, position = 23), Token(type = COMMA, value = ,, position = 27), Token(type = IDENTIFIER, value = age, position = 29), Token(type = RPAREN, value = ), position = 32), Token(type = KEYWORD, value = VALUES, position = 34), Token(type = LPAREN, value = (, position = 41), Token(type = NUMBER, value = 1, position = 42), Token(type = COMMA, value = ,, position = 43), Token(type = QUOTE, value = ', position = 45), Token(type = IDENTIFIER, value = John, position = 46), Token(type = IDENTIFIER, value = Doe, position = 51), Token(type = QUOTE, value = ', position = 54), Token(type = COMMA, value = ,, position = 55), Token(type = NUMBER, value = 30, position = 57), Token(type = RPAREN, value = ), position = 59), Token(type = SEMICOLON, value = ;, position = 60)]
2025-05-05 04:25:18,938 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 04:25:18,939 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 04:25:18,939 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 04:25:18,939 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:25:18,939 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 04:25:18,939 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 04:26:12,927 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:26:12,934 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-05 04:26:12,934 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:26:12,934 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 04:26:12,934 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-05 04:26:12,934 - compiler.parser - DEBUG - Table Name Found: products
2025-05-05 04:26:12,934 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = products, position = 7)
2025-05-05 04:26:12,934 - compiler.statements.update_parser - DEBUG - UPDATE table: products
2025-05-05 04:26:12,934 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-05 04:28:38,164 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:28:38,166 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:29:33,704 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:29:33,709 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:30:50,991 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:30:50,995 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:32:51,700 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:32:51,706 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:33:26,947 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:33:26,955 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:33:45,766 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:33:45,774 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:33:57,925 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:33:57,932 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:34:38,228 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:34:38,234 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:37:06,765 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:37:06,774 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:37:23,696 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:37:23,704 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:37:23,704 - compiler.statements.update_parser - ERROR - Unexpected token after UPDATE: Token(type = KEYWORD, value = SET, position = 16)
2025-05-05 04:39:27,987 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:39:27,993 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:40:30,711 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:40:30,717 - compiler.statements.update_parser - DEBUG - Starting to parse UPDATE statement...
2025-05-05 04:40:30,717 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:40:30,717 - compiler.statements.update_parser - DEBUG - Moved past UPDATE token.
2025-05-05 04:40:30,717 - compiler.statements.update_parser - DEBUG - Current token after UPDATE: Token(type = KEYWORD, value = SET, position = 16)
2025-05-05 04:40:30,717 - compiler.statements.update_parser - ERROR - Expected table name after UPDATE.
2025-05-05 04:41:23,136 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:41:23,137 - compiler.statements.update_parser - DEBUG - Starting to parse UPDATE statement...
2025-05-05 04:41:23,142 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:41:23,142 - compiler.statements.update_parser - DEBUG - Current token after UPDATE: Token(type = KEYWORD, value = SET, position = 16)
2025-05-05 04:41:23,142 - compiler.statements.update_parser - ERROR - Expected table name after UPDATE.

x
2025-05-05 04:44:34,646 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:44:34,654 - compiler.statements.update_parser - DEBUG - Starting to parse UPDATE statement...
2025-05-05 04:44:34,655 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:44:34,655 - compiler.statements.update_parser - DEBUG - Current token after UPDATE: Token(type = KEYWORD, value = SET, position = 16)
2025-05-05 04:44:34,655 - compiler.statements.update_parser - ERROR - Expected table name after UPDATE.
2025-05-05 04:45:54,240 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:45:54,248 - compiler.statements.update_parser - DEBUG - Starting to parse UPDATE statement...
2025-05-05 04:45:54,249 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:45:54,250 - compiler.statements.update_parser - DEBUG - Current token after UPDATE: Token(type = KEYWORD, value = SET, position = 16)
2025-05-05 04:45:54,250 - compiler.statements.update_parser - ERROR - Expected table name after UPDATE.
2025-05-05 04:46:28,490 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:46:28,494 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-05 04:46:28,494 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:46:28,495 - compiler.statements.update_parser - DEBUG - Table name identified: products
2025-05-05 04:46:28,495 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-05 04:46:28,495 - compiler.statements.update_parser - DEBUG - SET clause: {}
2025-05-05 04:47:28,962 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:47:28,965 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-05 04:47:28,968 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:47:28,968 - compiler.statements.update_parser - DEBUG - Table name identified: products
2025-05-05 04:47:28,968 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-05 04:47:28,968 - compiler.statements.update_parser - DEBUG - SET clause: {}
2025-05-05 04:48:22,938 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:48:22,946 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-05 04:48:22,946 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:48:22,946 - compiler.statements.update_parser - DEBUG - Table name identified: products
2025-05-05 04:48:22,946 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-05 04:48:22,946 - compiler.statements.update_parser - DEBUG - SET clause: {}
2025-05-05 04:49:45,352 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:49:45,357 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:50:18,735 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:50:18,740 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:50:36,334 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:50:36,335 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-05 04:50:36,335 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:50:36,335 - compiler.statements.update_parser - DEBUG - Table name identified: products
2025-05-05 04:50:36,341 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-05 04:50:36,341 - compiler.statements.update_parser - DEBUG - SET clause: {}
2025-05-05 04:50:45,171 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = products, position = 7), Token(type = KEYWORD, value = SET, position = 16), Token(type = IDENTIFIER, value = price, position = 20), Token(type = EQUALS, value = =, position = 26), Token(type = NUMBER, value = 2.00, position = 28), Token(type = KEYWORD, value = WHERE, position = 33), Token(type = IDENTIFIER, value = product_id, position = 39), Token(type = EQUALS, value = =, position = 50), Token(type = NUMBER, value = 101, position = 52), Token(type = SEMICOLON, value = ;, position = 55)]
2025-05-05 04:50:45,175 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-05 04:50:45,177 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:50:45,177 - compiler.statements.update_parser - DEBUG - Table name identified: products
2025-05-05 04:50:45,177 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 16)
2025-05-05 04:50:45,177 - compiler.statements.update_parser - DEBUG - SET clause: {}
2025-05-05 04:52:19,170 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = employees, position = 13), Token(type = LPAREN, value = (, position = 23), Token(type = IDENTIFIER, value = employee_id, position = 25), Token(type = KEYWORD, value = INT, position = 37), Token(type = IDENTIFIER, value = PRIMARY, position = 41), Token(type = IDENTIFIER, value = KEY, position = 49), Token(type = COMMA, value = ,, position = 52), Token(type = IDENTIFIER, value = name, position = 54), Token(type = IDENTIFIER, value = VARCHAR, position = 59), Token(type = LPAREN, value = (, position = 66), Token(type = NUMBER, value = 100, position = 67), Token(type = RPAREN, value = ), position = 70), Token(type = COMMA, value = ,, position = 71), Token(type = IDENTIFIER, value = salary, position = 73), Token(type = IDENTIFIER, value = DECIMAL, position = 80), Token(type = LPAREN, value = (, position = 87), Token(type = NUMBER, value = 10, position = 88), Token(type = COMMA, value = ,, position = 90), Token(type = NUMBER, value = 2, position = 92), Token(type = RPAREN, value = ), position = 93), Token(type = RPAREN, value = ), position = 95), Token(type = SEMICOLON, value = ;, position = 96)]
2025-05-05 04:52:19,179 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 04:52:19,179 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 04:52:19,179 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 04:52:19,179 - compiler.statements.create_parser - DEBUG - Table Name Found: employees
2025-05-05 04:52:19,179 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = employees, position = 13)
2025-05-05 04:52:19,179 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 23)
2025-05-05 04:52:19,179 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 04:52:19,179 - compiler.statements.create_parser - DEBUG - Column Found: employee_id
2025-05-05 04:52:19,179 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = employee_id, position = 25)
2025-05-05 04:52:19,179 - compiler.statements.create_parser - DEBUG - Column Type: INT
2025-05-05 04:52:19,179 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INT, position = 37)
2025-05-05 04:52:19,179 - compiler.statements.create_parser - ERROR - Expected ',' or ')' in column list
2025-05-05 04:52:44,218 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = employees, position = 13), Token(type = LPAREN, value = (, position = 23), Token(type = IDENTIFIER, value = employee_id, position = 25), Token(type = KEYWORD, value = INT, position = 37), Token(type = IDENTIFIER, value = PRIMARY, position = 41), Token(type = IDENTIFIER, value = KEY, position = 49), Token(type = RPAREN, value = ), position = 53), Token(type = SEMICOLON, value = ;, position = 54)]
2025-05-05 04:52:44,222 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 04:52:44,222 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 04:52:44,222 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 04:52:44,223 - compiler.statements.create_parser - DEBUG - Table Name Found: employees
2025-05-05 04:52:44,223 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = employees, position = 13)
2025-05-05 04:52:44,223 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 23)
2025-05-05 04:52:44,223 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 04:52:44,223 - compiler.statements.create_parser - DEBUG - Column Found: employee_id
2025-05-05 04:52:44,223 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = employee_id, position = 25)
2025-05-05 04:52:44,223 - compiler.statements.create_parser - DEBUG - Column Type: INT
2025-05-05 04:52:44,223 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INT, position = 37)
2025-05-05 04:52:44,223 - compiler.statements.create_parser - ERROR - Expected ',' or ')' in column list
2025-05-05 04:53:12,261 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = UPDATE, position = 0), Token(type = IDENTIFIER, value = employees, position = 7), Token(type = KEYWORD, value = SET, position = 17), Token(type = IDENTIFIER, value = salary, position = 21), Token(type = EQUALS, value = =, position = 28), Token(type = NUMBER, value = 55000, position = 30), Token(type = KEYWORD, value = WHERE, position = 36), Token(type = IDENTIFIER, value = employee_id, position = 42), Token(type = EQUALS, value = =, position = 54), Token(type = NUMBER, value = 101, position = 56), Token(type = SEMICOLON, value = ;, position = 59)]
2025-05-05 04:53:12,265 - compiler.statements.update_parser - INFO - Parsing UPDATE statement...
2025-05-05 04:53:12,268 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = UPDATE, position = 0)
2025-05-05 04:53:12,268 - compiler.statements.update_parser - DEBUG - Table name identified: employees
2025-05-05 04:53:12,268 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SET, position = 17)
2025-05-05 04:53:12,268 - compiler.statements.update_parser - DEBUG - SET clause: {}
2025-05-05 04:53:19,466 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = dingd, position = 13)]
2025-05-05 04:53:19,467 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 04:53:19,467 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 04:53:19,467 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 04:53:19,467 - compiler.statements.create_parser - DEBUG - Table Name Found: dingd
2025-05-05 04:53:19,467 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = dingd, position = 13)
2025-05-05 04:53:31,046 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = dingd, position = 13), Token(type = SEMICOLON, value = ;, position = 18)]
2025-05-05 04:53:31,046 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 04:53:31,046 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 04:53:31,046 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 04:53:31,046 - compiler.statements.create_parser - DEBUG - Table Name Found: dingd
2025-05-05 04:53:31,046 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = dingd, position = 13)
2025-05-05 04:53:31,049 - compiler.statements.create_parser - ERROR - Expected '(' after table name...

2025-05-05 04:54:32,945 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = dingd, position = 13), Token(type = LPAREN, value = (, position = 19)]
2025-05-05 04:54:32,949 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 04:54:32,949 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 04:54:32,949 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 04:54:32,949 - compiler.statements.create_parser - DEBUG - Table Name Found: dingd
2025-05-05 04:54:32,949 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = dingd, position = 13)
2025-05-05 04:54:32,949 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 19)
2025-05-05 04:54:32,949 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 04:54:43,796 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = dingd, position = 13), Token(type = LPAREN, value = (, position = 19)]
2025-05-05 04:54:43,798 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 04:54:43,798 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 04:54:43,798 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 04:54:43,798 - compiler.statements.create_parser - DEBUG - Table Name Found: dingd
2025-05-05 04:54:43,798 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = dingd, position = 13)
2025-05-05 04:54:43,798 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 19)
2025-05-05 04:54:43,798 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 04:54:52,163 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = dingd, position = 13), Token(type = LPAREN, value = (, position = 19)]
2025-05-05 04:54:52,166 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 04:54:52,166 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 04:54:52,167 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 04:54:52,167 - compiler.statements.create_parser - DEBUG - Table Name Found: dingd
2025-05-05 04:54:52,167 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = dingd, position = 13)
2025-05-05 04:54:52,167 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 19)
2025-05-05 04:54:52,167 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 04:55:11,551 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = CREATE, position = 0), Token(type = KEYWORD, value = TABLE, position = 7), Token(type = IDENTIFIER, value = dingd, position = 13), Token(type = LPAREN, value = (, position = 19), Token(type = IDENTIFIER, value = id, position = 21), Token(type = KEYWORD, value = INT, position = 24), Token(type = COMMA, value = ,, position = 27), Token(type = IDENTIFIER, value = name, position = 29), Token(type = IDENTIFIER, value = VARCHAR, position = 34), Token(type = LPAREN, value = (, position = 41), Token(type = NUMBER, value = 100, position = 42), Token(type = RPAREN, value = ), position = 45), Token(type = RPAREN, value = ), position = 47), Token(type = SEMICOLON, value = ;, position = 48)]
2025-05-05 04:55:11,557 - compiler.statements.create_parser - INFO - Parsing Create Table.... 

2025-05-05 04:55:11,557 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = CREATE, position = 0)
2025-05-05 04:55:11,557 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = TABLE, position = 7)
2025-05-05 04:55:11,557 - compiler.statements.create_parser - DEBUG - Table Name Found: dingd
2025-05-05 04:55:11,557 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = dingd, position = 13)
2025-05-05 04:55:11,557 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 19)
2025-05-05 04:55:11,557 - compiler.statements.create_parser - DEBUG - Parsing Columns.....

2025-05-05 04:55:11,557 - compiler.statements.create_parser - DEBUG - Column Found: id
2025-05-05 04:55:11,557 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = id, position = 21)
2025-05-05 04:55:11,557 - compiler.statements.create_parser - DEBUG - Column Type: INT
2025-05-05 04:55:11,557 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INT, position = 24)
2025-05-05 04:55:11,557 - compiler.statements.create_parser - DEBUG - Found ',' moving to next column....
2025-05-05 04:55:11,557 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 27)
2025-05-05 04:55:11,557 - compiler.statements.create_parser - DEBUG - Column Found: name
2025-05-05 04:55:11,557 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = name, position = 29)
2025-05-05 04:55:11,557 - compiler.statements.create_parser - ERROR - Expected column type (e.g., INT, TEXT), but got IDENTIFIER - VARCHAR
2025-05-05 04:57:20,540 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = hh, position = 7), Token(type = KEYWORD, value = FROM, position = 10), Token(type = IDENTIFIER, value = dknd, position = 15)]
2025-05-05 04:57:20,544 - compiler.statements.select_parser - DEBUG - Parsing SELECT statement...
2025-05-05 04:57:20,544 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 04:58:14,360 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = hh, position = 7), Token(type = KEYWORD, value = FROM, position = 10), Token(type = IDENTIFIER, value = dknd, position = 15)]
2025-05-05 04:58:14,365 - compiler.statements.select_parser - DEBUG - Parsing SELECT statement...
2025-05-05 04:58:14,365 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 04:58:30,761 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = hh, position = 7), Token(type = KEYWORD, value = FROM, position = 10), Token(type = IDENTIFIER, value = dknd, position = 15)]
2025-05-05 04:58:30,763 - compiler.statements.select_parser - DEBUG - Parsing SELECT statement...
2025-05-05 04:58:30,763 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 05:01:15,285 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = hh, position = 7), Token(type = KEYWORD, value = FROM, position = 10), Token(type = IDENTIFIER, value = dknd, position = 15)]
2025-05-05 05:01:15,287 - compiler.statements.select_parser - DEBUG - Parsing SELECT statement...
2025-05-05 05:01:15,288 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 05:01:15,288 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 10)
2025-05-05 05:01:53,156 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = hh, position = 7), Token(type = KEYWORD, value = FROM, position = 10), Token(type = IDENTIFIER, value = dknd, position = 15)]
2025-05-05 05:01:53,159 - compiler.statements.select_parser - DEBUG - Parsing SELECT statement...
2025-05-05 05:01:53,159 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 05:01:53,159 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 10)
2025-05-05 05:01:53,159 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = dknd, position = 15)
2025-05-05 05:02:14,012 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DROP, position = 0), Token(type = IDENTIFIER, value = me, position = 5)]
2025-05-05 05:02:14,014 - compiler.statements.drop_parser - INFO - Parsing DROP statement....
2025-05-05 05:02:14,014 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DROP, position = 0)
2025-05-05 05:02:14,014 - compiler.statements.drop_parser - DEBUG - Dropped Entity: me
2025-05-05 05:02:14,014 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = me, position = 5)
2025-05-05 05:02:19,500 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DROP, position = 0), Token(type = IDENTIFIER, value = me, position = 5), Token(type = SEMICOLON, value = ;, position = 7)]
2025-05-05 05:02:19,503 - compiler.statements.drop_parser - INFO - Parsing DROP statement....
2025-05-05 05:02:19,503 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DROP, position = 0)
2025-05-05 05:02:19,503 - compiler.statements.drop_parser - DEBUG - Dropped Entity: me
2025-05-05 05:02:19,503 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = me, position = 5)
2025-05-05 05:02:19,503 - compiler.statements.drop_parser - INFO - DROP parsed: entity = me
2025-05-05 05:02:29,888 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = IDENTIFIER, value = me, position = 7), Token(type = SEMICOLON, value = ;, position = 9)]
2025-05-05 05:02:29,891 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 05:02:29,891 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 05:02:29,891 - compiler.statements.delete_parser - ERROR - Expected 'FROM' after DELETE...
2025-05-05 05:02:39,251 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = me, position = 12), Token(type = KEYWORD, value = WHERE, position = 15), Token(type = IDENTIFIER, value = me, position = 21)]
2025-05-05 05:02:39,253 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 05:02:39,255 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 05:02:39,255 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 7)
2025-05-05 05:02:39,255 - compiler.statements.delete_parser - DEBUG - Token before table_name: Token(type = IDENTIFIER, value = me, position = 12)
2025-05-05 05:02:39,255 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 05:02:39,255 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = me, position = 12)
2025-05-05 05:02:39,255 - compiler.parser - DEBUG - Table Name Found: me
2025-05-05 05:02:39,255 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = me, position = 12)
2025-05-05 05:02:39,255 - compiler.statements.delete_parser - DEBUG - DELETE FROM: me
2025-05-05 05:02:39,255 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 15)
2025-05-05 05:02:39,255 - compiler.parser - DEBUG - Parsing WHERE condition....
2025-05-05 05:02:39,255 - compiler.parser - DEBUG - Column Found: me
2025-05-05 05:02:39,255 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = me, position = 21)
2025-05-05 05:02:43,560 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = me, position = 12), Token(type = KEYWORD, value = WHERE, position = 15), Token(type = IDENTIFIER, value = me, position = 21), Token(type = SEMICOLON, value = ;, position = 23)]
2025-05-05 05:02:43,563 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 05:02:43,563 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 05:02:43,563 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 7)
2025-05-05 05:02:43,563 - compiler.statements.delete_parser - DEBUG - Token before table_name: Token(type = IDENTIFIER, value = me, position = 12)
2025-05-05 05:02:43,563 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 05:02:43,563 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = me, position = 12)
2025-05-05 05:02:43,563 - compiler.parser - DEBUG - Table Name Found: me
2025-05-05 05:02:43,565 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = me, position = 12)
2025-05-05 05:02:43,565 - compiler.statements.delete_parser - DEBUG - DELETE FROM: me
2025-05-05 05:02:43,565 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = WHERE, position = 15)
2025-05-05 05:02:43,565 - compiler.parser - DEBUG - Parsing WHERE condition....
2025-05-05 05:02:43,565 - compiler.parser - DEBUG - Column Found: me
2025-05-05 05:02:43,565 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = me, position = 21)
2025-05-05 05:02:43,565 - compiler.parser - ERROR - Expected '=' after column name in WHERE clause.
2025-05-05 05:02:48,870 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = DELETE, position = 0), Token(type = KEYWORD, value = FROM, position = 7), Token(type = IDENTIFIER, value = me, position = 12), Token(type = SEMICOLON, value = ;, position = 15)]
2025-05-05 05:02:48,875 - compiler.statements.delete_parser - INFO - Parsing DELETE statement....
2025-05-05 05:02:48,875 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = DELETE, position = 0)
2025-05-05 05:02:48,875 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 7)
2025-05-05 05:02:48,875 - compiler.statements.delete_parser - DEBUG - Token before table_name: Token(type = IDENTIFIER, value = me, position = 12)
2025-05-05 05:02:48,876 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 05:02:48,876 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = me, position = 12)
2025-05-05 05:02:48,876 - compiler.parser - DEBUG - Table Name Found: me
2025-05-05 05:02:48,876 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = me, position = 12)
2025-05-05 05:02:48,876 - compiler.statements.delete_parser - DEBUG - DELETE FROM: me
2025-05-05 05:02:48,876 - compiler.statements.delete_parser - INFO - DELETE parsed: table = me, WHERE condition = None
2025-05-05 05:03:30,784 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = me, position = 14)]
2025-05-05 05:03:30,786 - compiler.statements.select_parser - DEBUG - Parsing SELECT statement...
2025-05-05 05:03:30,786 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 05:03:54,550 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = ASTERISK, value = *, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = me, position = 15), Token(type = SEMICOLON, value = ;, position = 17)]
2025-05-05 05:03:54,550 - compiler.statements.select_parser - DEBUG - Parsing SELECT statement...
2025-05-05 05:03:54,550 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 05:04:21,647 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = SELECT, position = 0), Token(type = IDENTIFIER, value = t, position = 7), Token(type = KEYWORD, value = FROM, position = 9), Token(type = IDENTIFIER, value = me, position = 15), Token(type = SEMICOLON, value = ;, position = 17)]
2025-05-05 05:04:21,656 - compiler.statements.select_parser - DEBUG - Parsing SELECT statement...
2025-05-05 05:04:21,656 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = SELECT, position = 0)
2025-05-05 05:04:21,656 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = FROM, position = 9)
2025-05-05 05:04:21,657 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = me, position = 15)
2025-05-05 05:08:04,807 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = LPAREN, value = (, position = 18), Token(type = IDENTIFIER, value = id, position = 19), Token(type = COMMA, value = ,, position = 21), Token(type = IDENTIFIER, value = name, position = 23), Token(type = COMMA, value = ,, position = 27), Token(type = IDENTIFIER, value = age, position = 29), Token(type = RPAREN, value = ), position = 32), Token(type = KEYWORD, value = VALUES, position = 34), Token(type = LPAREN, value = (, position = 41), Token(type = NUMBER, value = 1, position = 42), Token(type = COMMA, value = ,, position = 43), Token(type = QUOTE, value = ', position = 45), Token(type = IDENTIFIER, value = John, position = 46), Token(type = IDENTIFIER, value = Doe, position = 51), Token(type = QUOTE, value = ', position = 54), Token(type = COMMA, value = ,, position = 55), Token(type = NUMBER, value = 30, position = 57), Token(type = RPAREN, value = ), position = 59), Token(type = SEMICOLON, value = ;, position = 60)]
2025-05-05 05:08:04,816 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 05:08:04,816 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 05:08:04,816 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 05:08:04,816 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 05:08:04,816 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 05:08:04,816 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 05:09:12,057 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = LPAREN, value = (, position = 18), Token(type = IDENTIFIER, value = id, position = 19), Token(type = COMMA, value = ,, position = 21), Token(type = IDENTIFIER, value = name, position = 23), Token(type = COMMA, value = ,, position = 27), Token(type = IDENTIFIER, value = age, position = 29), Token(type = RPAREN, value = ), position = 32), Token(type = KEYWORD, value = VALUES, position = 34), Token(type = LPAREN, value = (, position = 41), Token(type = NUMBER, value = 1, position = 42), Token(type = COMMA, value = ,, position = 43), Token(type = QUOTE, value = ', position = 45), Token(type = IDENTIFIER, value = John, position = 46), Token(type = IDENTIFIER, value = Doe, position = 51), Token(type = QUOTE, value = ', position = 54), Token(type = COMMA, value = ,, position = 55), Token(type = NUMBER, value = 30, position = 57), Token(type = RPAREN, value = ), position = 59), Token(type = SEMICOLON, value = ;, position = 60)]
2025-05-05 05:09:12,070 - compiler.statements.insert_parser - DEBUG - Parsing INSERT statement...
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 18)
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 32)
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 34)
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 41)
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Found value: 1
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 42)
2025-05-05 05:09:12,070 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 43)
2025-05-05 05:10:09,792 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = LPAREN, value = (, position = 18), Token(type = IDENTIFIER, value = id, position = 19), Token(type = COMMA, value = ,, position = 21), Token(type = IDENTIFIER, value = name, position = 23), Token(type = COMMA, value = ,, position = 27), Token(type = IDENTIFIER, value = age, position = 29), Token(type = RPAREN, value = ), position = 32), Token(type = KEYWORD, value = VALUES, position = 34), Token(type = LPAREN, value = (, position = 41), Token(type = NUMBER, value = 1, position = 42), Token(type = COMMA, value = ,, position = 43), Token(type = QUOTE, value = ', position = 45), Token(type = IDENTIFIER, value = John, position = 46), Token(type = IDENTIFIER, value = Doe, position = 51), Token(type = QUOTE, value = ', position = 54), Token(type = COMMA, value = ,, position = 55), Token(type = NUMBER, value = 30, position = 57), Token(type = RPAREN, value = ), position = 59), Token(type = SEMICOLON, value = ;, position = 60)]
2025-05-05 05:10:09,799 - compiler.statements.insert_parser - DEBUG - Parsing INSERT statement...
2025-05-05 05:10:09,799 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 05:10:09,799 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 05:10:09,799 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 05:10:09,799 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 05:10:09,799 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 05:10:09,799 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 05:10:09,800 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 18)
2025-05-05 05:10:09,800 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 32)
2025-05-05 05:10:09,800 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 34)
2025-05-05 05:10:09,800 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 41)
2025-05-05 05:10:09,800 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 42)
2025-05-05 05:10:09,800 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 43)
2025-05-05 05:10:32,316 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = LPAREN, value = (, position = 18), Token(type = IDENTIFIER, value = id, position = 19), Token(type = COMMA, value = ,, position = 21), Token(type = IDENTIFIER, value = name, position = 23), Token(type = COMMA, value = ,, position = 27), Token(type = IDENTIFIER, value = age, position = 29), Token(type = RPAREN, value = ), position = 32), Token(type = KEYWORD, value = VALUES, position = 34), Token(type = LPAREN, value = (, position = 41), Token(type = NUMBER, value = 1, position = 42), Token(type = COMMA, value = ,, position = 43), Token(type = QUOTE, value = ', position = 45), Token(type = IDENTIFIER, value = John, position = 46), Token(type = IDENTIFIER, value = Doe, position = 51), Token(type = QUOTE, value = ', position = 54), Token(type = COMMA, value = ,, position = 55), Token(type = NUMBER, value = 30, position = 57), Token(type = RPAREN, value = ), position = 59), Token(type = SEMICOLON, value = ;, position = 60)]
2025-05-05 05:10:32,326 - compiler.statements.insert_parser - DEBUG - Parsing INSERT statement...
2025-05-05 05:10:32,326 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 05:10:32,326 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 05:10:32,326 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 05:10:32,326 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 05:10:32,326 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 05:10:32,326 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 05:10:32,326 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 18)
2025-05-05 05:10:32,326 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 32)
2025-05-05 05:10:32,326 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 34)
2025-05-05 05:10:32,326 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 41)
2025-05-05 05:10:32,326 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 42)
2025-05-05 05:10:32,326 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 43)
2025-05-05 05:12:08,928 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = LPAREN, value = (, position = 18), Token(type = IDENTIFIER, value = id, position = 19), Token(type = COMMA, value = ,, position = 21), Token(type = IDENTIFIER, value = name, position = 23), Token(type = COMMA, value = ,, position = 27), Token(type = IDENTIFIER, value = age, position = 29), Token(type = RPAREN, value = ), position = 32), Token(type = KEYWORD, value = VALUES, position = 34), Token(type = LPAREN, value = (, position = 41), Token(type = NUMBER, value = 1, position = 42), Token(type = COMMA, value = ,, position = 43), Token(type = QUOTE, value = ', position = 45), Token(type = IDENTIFIER, value = John, position = 46), Token(type = IDENTIFIER, value = Doe, position = 51), Token(type = QUOTE, value = ', position = 54), Token(type = COMMA, value = ,, position = 55), Token(type = NUMBER, value = 30, position = 57), Token(type = RPAREN, value = ), position = 59), Token(type = SEMICOLON, value = ;, position = 60)]
2025-05-05 05:12:08,937 - compiler.statements.insert_parser - DEBUG - Parsing INSERT statement...
2025-05-05 05:12:08,937 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 05:12:08,937 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 05:12:08,937 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 05:12:08,937 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 05:12:08,937 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 05:12:08,937 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 05:12:08,937 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 18)
2025-05-05 05:12:08,937 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 32)
2025-05-05 05:12:08,937 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 34)
2025-05-05 05:12:08,937 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 41)
2025-05-05 05:12:08,937 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 42)
2025-05-05 05:12:08,937 - compiler.parser - DEBUG - Processed token: Token(type = COMMA, value = ,, position = 43)
2025-05-05 05:12:44,359 - compiler.tokenizer - INFO - Tokenized successfully: [Token(type = KEYWORD, value = INSERT, position = 0), Token(type = KEYWORD, value = INTO, position = 7), Token(type = IDENTIFIER, value = users, position = 12), Token(type = LPAREN, value = (, position = 18), Token(type = IDENTIFIER, value = id, position = 19), Token(type = RPAREN, value = ), position = 21), Token(type = KEYWORD, value = VALUES, position = 23), Token(type = LPAREN, value = (, position = 30), Token(type = NUMBER, value = 1, position = 31), Token(type = RPAREN, value = ), position = 32), Token(type = SEMICOLON, value = ;, position = 33)]
2025-05-05 05:12:44,360 - compiler.statements.insert_parser - DEBUG - Parsing INSERT statement...
2025-05-05 05:12:44,360 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INSERT, position = 0)
2025-05-05 05:12:44,360 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = INTO, position = 7)
2025-05-05 05:12:44,360 - compiler.parser - DEBUG - Parsing table name....
2025-05-05 05:12:44,360 - compiler.parser - DEBUG - Current token in table_name: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 05:12:44,360 - compiler.parser - DEBUG - Table Name Found: users
2025-05-05 05:12:44,360 - compiler.parser - DEBUG - Processed token: Token(type = IDENTIFIER, value = users, position = 12)
2025-05-05 05:12:44,360 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 18)
2025-05-05 05:12:44,360 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 21)
2025-05-05 05:12:44,360 - compiler.parser - DEBUG - Processed token: Token(type = KEYWORD, value = VALUES, position = 23)
2025-05-05 05:12:44,360 - compiler.parser - DEBUG - Processed token: Token(type = LPAREN, value = (, position = 30)
2025-05-05 05:12:44,360 - compiler.parser - DEBUG - Processed token: Token(type = NUMBER, value = 1, position = 31)
2025-05-05 05:12:44,360 - compiler.parser - DEBUG - Processed token: Token(type = RPAREN, value = ), position = 32)
2025-05-05 05:12:44,364 - compiler.parser - DEBUG - Processed token: Token(type = SEMICOLON, value = ;, position = 33)
2025-05-05 05:12:44,366 - compiler.code_generator - DEBUG - Generating execution plan for: InsertCommand
2025-05-05 05:12:44,366 - compiler.code_generator - DEBUG - Generating plan for INSERT command on table users
